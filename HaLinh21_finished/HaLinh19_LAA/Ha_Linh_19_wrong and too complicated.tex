% Editing tex file using vim in bash mode and then commit it with git

%%%%%%%%%%%class file
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
\usepackage[10pt]{extsizes}

%\smartqed % flush right qed marks, e.g. at end of proof
%%%%%%%%%%%%%%%%%
%call  packages
\usepackage[sort&compress]{natbib}
\usepackage{lipsum}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pdfoutput=1
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algcompatible}

%\usepackage[notcite]{showkeys}
%\usepackage{color}
%\usepackage{showlabels}
%\renewcommand{\showlabelfont}{\small\slshape\color{red}}

\usepackage{lineno}
\linenumbers

\usepackage{graphicx}
\usepackage{amssymb,amsmath,bm,mathrsfs}
\let\proof\relax\let\endproof\relax
% Using the package amsthm leads to confliction ''The \begin{proof} is already defined''
\usepackage{amsthm}
\usepackage{mathabx}
\usepackage{hyperref} %$#

%%%%%%%%%%%%%%%%%

%Math environments===========================================================
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{example}[theorem]{Example}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{remark}[theorem]{Remark}
%\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{hypo}[theorem]{Hypothesis}
\renewcommand{\labelenumi}{\roman{enumi}}
\numberwithin{equation}{section}
\newtheorem{procedure}[theorem]{Procedure}

\include{command}

%===============================================================================
\begin{document}
	
%\title{Regularization of Second Order Singular Difference Equations\footnotemark[1]}
%\titlerunning{Regularization of Second Order Singular Difference Equations}% Part of RIGHT running header
\title{Solvability Analysis of Second Order, Discrete Time Descriptor Systems \footnotemark[1]}
\titlerunning{Solvability Analysis of Second Order, Discrete Time Descriptor Systems} % Part of RIGHT running header
\author{ {\sc Phi Ha %\thanks{This work was supported by the research project Naforsted, and was done during the first author's visit at VIASM}
	and Vu Hoang Linh}}
	%\authorrunning{Short author list}% Part of LEFT running header

\institute{Phi Ha and Vu Hoang Linh \at Institute of Math-Mechanics-Informatics, Hanoi University of Science, VNU \\ 	Nguyen Trai Street 334, Thanh Xuan, Hanoi, Vietnam\\ 
		\email{\{haphi.hus;linhvu\}@vnu.edu.vn}
	}
\date{Received: date / Accepted: date}      
	
\maketitle
	
\begin{abstract}
This paper is devoted to the analysis of linear, second order \emph{discrete time descriptor systems} (or singular difference equations (SiDEs) with control). 
Following the algebraic approach proposed in \cite{KunM94a,KunM94b}, first we present a theoretical framework to analyze the corresponding initial value problem for SiDEs, which is followed by the analysis of descriptor systems.
We also describe numerical methods to determine the structural properties related to the solvability analysis of these systems. 
%Finally, we discuss the regularizability and impulse-controllability of descriptor systems via different types of feedbacks. 
This work extends and completes the researches in  \cite{Bru09,MehS06,LosM08}.
\end{abstract}
	
\noindent
{\bf Keywords:} Singular systems; Difference equation; Descriptor systems; \linebreak Strangeness-index; Regularization; Feedback.

\noindent
{\bf AMS Subject Classification:} 34A09, 34A12, 65L05, 65H10
%===============================================================================

\section{Introduction and Preliminaries}\label{intro}

In this paper we study second order, discrete time descriptor systems of the form
%
\begin{equation}\label{eq1.0}
A_n x(n+2) + B_{n} x(n+1) + C_{n} x(n) + D_{n} u(n)  = f(n),\ \mbox{ for all } n \geq n_0. 
\end{equation}
%
We will also discuss the initial value problem of the associated singular difference equation (SiDE) 
%
\begin{equation}\label{eq1.1}
A_n x(n+2) + B_{n} x(n+1) + C_{n} x(n) = f(n),\ \mbox{ for all } n \geq n_0,
\end{equation}
%
together with some given initial conditions
%
\begin{equation}\label{eq1.2}
x(n_0+1)=x_{1}, \ x(n_0)=x_{0}.
\end{equation}
%
Here the solution/state $x=\{ x(n) \}_{n\geq n_0}$, the inhomogeneity $f=\{ f(n) \}_{n\geq n_0}$, the input function $u=\{ u(n) \}_{n\geq n_0}$, where $x(n) \in \r^d$, $f(n) \in \r^m$ and $u(n) \in \r^p$ for each $n \geq n_0$. The coefficients contain three matrix sequences $\{A_{n}\}_{n\geq n_0}$, $\{B_{n}\}_{n\geq n_0}$, $\{C_{n}\}_{n\geq n_0}$ which always take values in $\r^{m,d}$, and $\{D_{n}\}_{n\geq n_0}$ which take values in $\r^{m,p}$. 
We notice, that all the results in this paper also carry over to the complex case, and they can also be easily extended to systems of higher than second order, but for ease of notation and because this is the most important case in practice, we restrict ourselves to the real second order case.

The SiDE \eqref{eq1.1}, on one side, can be consider as the resulting equations, obtained by finite difference or discretization of some continuous-time DAEs or constrained PDEs. One the other side, there are also many models/applications in real-life, which lead to SiDEs, for example Leotief economic models, backward Leslie model in biology, etc. 

While both DAEs and SiDEs of first order have been well-studied from both theoretical and numerical sides,
the same maturity has not been reached for higher order systems. 
In classical literatures \cite{Aga00,Ela13,Kel01}, usually new variables are introduced to present some chosen derivatives of the state variable $x$ such that a high order system can be reformulated as a first order one. This method, however, is not only non-unique but also has presented some substantial disadvantages. As have been fully discussed in \cite{LosM08,MehS06} for continuous time systems, these disadvantages include: (1st) increase the index of the system, and therefore the complexity of the numerical method to solve it; (2nd) increase the computational effort, because of the bigger size of a new system; (3rd) affect the controllability/observability of the corresponding descriptor system, since there exist situations where a new system is uncontrollable while the original one is. 
%%This fact is well-known for continuous time systems (e.g. \cite{LosM08}), where one can control just the state in a multi-body system but not always its velocity. 
%Moreover, introducing new variables may also require associated initial conditions, which is not always available. For example one cannot require an initial condition of an input function. 
Therefore, the \emph{algebraic approach}, which treats the system directly without reformulating it, has been presented in \cite{LosM08,MehS06,Wun06,Wun08} in order to overcome the disadvantages mentioned above.
Nevertheless, even for second order SiDEs, this method has not yet been considered.


Another motivation of this work comes from recent researches on the stability analysis of high order discrete time systems with time-dependent coefficients \cite{LinNT16,MehT15}. There, considered systems are in either strangeness-free form or linear state-space form. Nevertheless, it is not always the case in applications, and hence, a reformulation procedure is necessary.

%Another motivation of this work comes from recent researches on the qualitative properties of high order discrete time systems with time-dependent coefficients, such as stability analysis (e.g. \cite{LinNT16,MehT15}), or control properties (e.g. \cite{KarG14,LiuF12,MoyKA19}). There, considered systems are in strangeness-free form (or state-space form). Nevertheless, it is not always the case in applications, and hence, a reformulation procedure is necessary.

%these disadvantages include: (1st) increase the index of the system, and therefore the complexity of the numerical method to solve it; (2nd) increase the computational effort, because of the bigger size of a new system; (3rd) affect the controllability/observability of the given system, since there exist situations where a new system is uncontrollable while the original one is. 
%%This fact is well-known for continuous time systems (e.g. \cite{LosM08}), where one can control just the state in a multi-body system but not always its velocity. 
%Moreover, introducing new variables may also require associated initial conditions, which is not always available. For example one cannot require an initial condition of an input function. 
%
%The algebraic approach, which treats the system directly without reformulating it, 
%has demonstrated its applicability to overcome the disadvantages above, as has been contemplated in \cite{LosM08,MehS06,Wun06,Wun08}. 
%
Therefore, the main aim of this article is to set up a comparable framework for second order SiDEs/descriptor systems. It is worth marking that the algebraic method proposed in \cite{MehS06,LosM08} is applicable theoretically but not numerically, due to two reasons: (1) The condensed form of the matrix coefficients are very big and complicated. (2) The system's transformations are not unitary. In this work, we will modify this method to make it more concise and also be computable in a stable way.    

The outline of this paper is as follows. After recalling some preliminary concepts and some auxiliary lemmata, in Sections \ref{Sec2} and \ref{Sec2b} we consecutively introduce \emph{index reduction procedures} for SiDEs and for descriptor systems, based on condensed forms that allow us to determine structural properties such as existence and uniqueness of a solution, consistency and hidden constraints, etc.
For the numerical solution of these systems, we consider in Section \ref{Sec3} the \emph{difference array approach} to bring the original system to its strangeness-free form. The presented algorithms are demonstrated by numerical experiments. 
%In \ref{Sec4} we discuss the regularization and impulse-controllability of descriptor systems via different types of feedback control. In particular, we establish verifiable conditions for the impulse controllability in terms of the system's coefficients.  
Finally, we finish with some conclusion.\\

In the following example we demonstrate some difficulties that may arise in the analysis of second order SiDEs.
%
\begin{example}\label{Exa2}
Consider the following second order SiDE, motivated from Example 2, \cite{MehS06}.
%
\[
\m{1 & 0 \\ 0 & 0} x(n+2) + \m{1 & 0 \\ 0 & 0} x(n+1) + \m{0 & 1 \\ 1 & 0} x(n) = \m{f_1(n) \\ f_2(n)}, \ n\geq n_0.  
\]
%
Clearly, from the second equation $\m{1 & 0} x(n) = f_2(n)$, we can shift the time $n$ to obtain 
%
\[
 \m{1 & 0} x(n+1) = f_2(n+1)  \ \mbox{ and } \ \m{1 & 0} x(n+2) = f_2(n+2).
\]
%
Inserting these to the first equation of the original system, we find out the hidden constraint $f_2(n+2) + f_2(n+1) + \m{0 & 1} x(n) = f_1(n)$. 
Consequently, we obtain the following system, which possess a unique solution
%
\[
 \m{0 & 1 \\ 1 & 0} x(n) = \m{f_1(n) -f_2(n+2) - f_2(n+1)  \\ f_2(n)}, \ n\geq n_0.
\]
%
Let $n=n_0$ in this new system, we obtain a constraint that $x(n_0)$ must obey.
This example showed us some important facts. Firstly, one can use some shift operators and row-manipulation (Gaussian eliminations) to derive hidden constraints. Secondly, the solution only exists if the initial condition fulfills some consistency conditions.
\end{example}

For matrices $Q\in \r^{q,d}$, $P\in\r^{p,d}$, the pair $(Q,P)$ is said to
\emph{have no hidden redundancy} if
%
\[
\rm{rank} \left(\m{Q \\ P} \right) = \rm{rank} (Q) + \rm{rank}(P).
\]
%
Otherwise, $(Q,P)$ is said to \emph{have hidden redundancy}.
%
The geometrical meaning of this concept is that the intersection space $\vspan(P^T) \cap \vspan(Q^T)$ contains only the zero-vector $\vec{0}$. Here by $\vspan(P^T)$ (resp., $\vspan(Q^T)$) we denote the real vector space spanned by the rows of $P$ (resp., rows of $Q$). \ We further notice that, if $\m{Q \\ P}$ is of full row rank then obviously, the pair $(Q,P)$ has no hidden redundancy. However, the converse is not true as is obvious for $Q=\m{1 & 0 \\ 0 & 0}$, $P=\m{0 & 1 \\ 0 & 0}$.


\begin{lemma}\label{lem1.1}(\cite{HaM12}) Suppose that for  $Q \in \r^{q,d}$, $P\in\r^{p,d}$, the pair
$(Q,P)$ has no hidden redundancy. Then, for any matrix $U\in C^{q,q}$ and any $V \in C^{p,p}$, the pair
$(UQ,VP)$ has no hidden redundancy.
\end{lemma}

\begin{lemma}\label{lem1.3}(\cite{HaM12})
	Consider $k+1$ full row rank matrices $R_0 \in \r^{r_0,d},\dots, R_k \in \r^{r_k,d}$, and assume that for $j=k,\dots,1$ none of the matrix pairs $\left(R_j, \m{R_{j-1} \\ \vdots \\ R_0} \right)$ has a hidden redundancy.
	Then, $\m{R_k \\ \vdots \\ R_0}$ has full row rank.
\end{lemma}

Lemma \ref{lem1.2} below will be very useful later for our analysis, in order to remove hidden redundancy in the coefficients of \eqref{eq1.1}.

\begin{lemma}\label{lem1.2}
For $Q\in \r^{q,d}$, $P\in\r^{p,d}$, there exists $\m{S & 0 \\ Z_1 & Z_2} \in \r^{q,q+p}$ such that the following conditions hold.
\begin{enumerate}
	\item[i)] $\m{S \\ Z_1}$ is unitary, and $Z_1 P + Z_2 Q = 0$,
	\item[ii)] the matrix $SP$ has full row rank, and the pair $(SP,Q)$ has no hidden redundancy.
\end{enumerate}
	%
\end{lemma}
%
\begin{proof} First using SVD we factorize $Q$ and then partition $P$ conformably to get
%
\begin{equation}\label{eq2.4}
U_1^H  Q V_1 = \m{\Si & 0 \\ 0 & 0 }, \ \mbox{and} \ PV_1 = \m{P_1 & P_2},
\end{equation}
%
where $U_1=\m{U_{11} & U_{12}} \in \r^{q,q}, \ V_1=\m{V_{11} & V_{12}} \in \r^{d,d}$ are unitary and $\Si \in \r^{r_Q,r_Q}$ is diagonal. 
Now we use a second SVD to factorize $P_2$ and to find a unitary matrix $U^H_2= \m{S \\ Z_1} \in \r^{p,p}$ such that $U_2^H P_2 = \m{P_{12} \\ 0}$, where $P_{12}$ has full row rank. 
Thus, we obtain
%
\[
\m{S & 0 \\ Z_1 & 0 \\ 0 & U_{11}^H \\ 0 & U_{12}^H} \m{P \\ \hline  Q} \m{V_{11} & V_{12}} =
\m{
	P_{11} & P_{12} \\
	P_{21} & 0 \\ \hline
	\Si & 0 \\
	0   & 0
}.
\]
%
Since $P_{12}$ has full row rank, $SP=\m{P_{11} & P_{12}}V_1^{-1}$ also has full row rank. Moreover, one sees that
%
\[ \rank \left( \m{SP \\ Q} \right) = \rank \left(\m{0 & P_{12}} \right) + \rank \left(\m{\Si & 0} \right) = \rank(SP) + \rank(Q),
\]
%
which follows that the pair $(SP,Q)$ has no hidden redundancy.\\
Finally, setting $Z_2 := - P_{21}\Si^{-1}U_{11}^H$, we obtain
%
\[ Z_1 P + Z_2Q = \left( [P_{21} \quad 0] - P_{21} \Si^{-1} [\Si \quad 0] \right) V_1^{-1} = 0, \]
%
which completes the proof.
\end{proof}

\begin{remark}\label{rem1}
	It should be noted, that the matrices $U_1$, $U_2$, $V_1$ in the proof of Lemma \ref{lem1.2} are orthogonal. Therefore, in case that the singular values of $Q$ are neither too small nor too big, then $\Si^{-1}$ is well-conditioned, and hence we can stably compute the matrix $Z_2$. Both matrices $Z_1$ and $Z_2$ will play the key role in our \emph{index reduction procedure} presented in the next section.
\end{remark}

For any given matrix $M$, by $M^T$ we denote its transpose. By $T_0(M)$ we denote an orthogonal matrix whose columns span the left null space of $M$. By $T_{\perp}(M)$ we denote an orthogonal matrix whose columns span the vector space $\range(M)$. 
%We notice that, even though these matrices are not uniquely determined, the left/right null spaces of $M$ are. Thus, for simplicity, we speak of these matrices as the corresponding spaces.
From basic linear algebra, we have the following three lemmata.

\begin{lemma}\label{lem1.4} The matrix $\m{T^T_{\perp}(M) \\ T^T_0(M)}$ is nonsingular, the matrix $T^T_{\perp}(M) \ M$ has full row rank, and the following identity holds
\[
\m{T^T_{\perp}(M) \\ T^T_0(M)} M = \m{T^T_{\perp}(M) \ M \\ 0 }.
\]
\end{lemma}
\begin{proof}
A simple proof can be found in, for example, \cite{GolV96}.
\end{proof}

\begin{lemma}\label{lem1.5} Given four matrices $\chA$, $\chB$, $\chC$ in $\r^{m,d}$ and $\chD$ in $\r^{m,p}$. Let us consider the following matrices whose columns span orthonormal bases of the associated vector spaces
	\[
	\begin{array}{lllll}
	T_{1} 	& \mbox{basis of } \kernel(\chA^T), 							& \mbox{ and } & T_{1,\perp} & \mbox{basis of } \range(\chA),			\\
	W_{1} 	& \mbox{basis of } \kernel(T_1^T \chD)^T,   					& \mbox{ and } & W_{1,\perp} & \mbox{basis of } \range(T_1^T \chD),		\\
    		&  																& 			   &  \Jd  	 & := W_{1,\perp}^T  T_{1}^T  \chD,       	\\       	       
     \Jbone  & := W_1^T T_1^T \chB, 											& \mbox{ and } &  \Jbtwo  	 & := W_{1,\perp}^T T_{1,\perp}^T \chB,   	\\
  	T_{2} 	& \mbox{basis of } \kernel( \Jbone)^T, 							& \mbox{ and } & T_{2,\perp} & \mbox{basis of } \range( \Jbone),			\\
	T_{3} 	& \mbox{basis of } \kernel( \Jbtwo)^T,							& \mbox{ and } & T_{3,\perp} & \mbox{basis of } \range( \Jbtwo), 		\\
	 \Jcone  & :=  W_{1}^T T_{1}^T \chC, 									& \mbox{ and } &  \Jctwo  	 & := W_{1,\perp}^T T_{1}^T \chC,           \\       
	T_{4} 	& \mbox{basis of } \kernel(T_{2}^T  \Jcone)^T, 					& \mbox{ and } & T_{4,\perp} & \mbox{basis of } \range(T_{2}^T  \Jcone).
	\end{array}
	\]
	Then, the following assertions hold true.
	\begin{enumerate}
		\item[i)] The matrices $\m{T_{i,\perp} \\ T_{i} }$, $i=1,...,4$, $\m{W_{1,\perp} \\ W_1}$ are orthogonal.
		\item[ii)]	The matrices $T_{1,\perp}^T \chA$, $T_{2,\perp}^T  \Jbone$,  $T_{3,\perp}^T  \Jbtwo$, $T^T_{4,\perp} T_{2}^T  \Jcone$, and $ \Jd$ have full row rank.
		\item[iii)] Moreover, there exists a nonsingular matrix $\chU$ such that 
		%
		\be\label{eq1.10}
		\chU \m{\chA & \chB & \chC & \vline & \chD}
		\!=\! \m{
			T_{1,\perp}^T \chA 	 & \ T_{1,\perp}^T \chB  		& \ T_{1,\perp}^T \chC  		& \vline & T_{1,\perp}^T \chD \\
			%	0 					 & \ T_{1}^T \chB 	 	 		& \ T_{1}^T \chC 		 		& \vline & T_{1}^T \chD 		\\
			%	0 					 & \  \Jbone 	 	& \  \Jcone 	 	& \vline & 0 \\
			0 					 & \ T_{2,\perp}^T  \Jbone 	 	& \ T_{2,\perp}^T  \Jcone 	 	& \vline & 0 \\
			0 					 & 0 	 						& \  T_{4,\perp}^T T_{2}^T  \Jcone 	 	& \vline & 0 \\ 
			0 					 & 0 	 						& 0												 	 	& \vline & 0 \\ \hline \\[-0.35cm]
			%	0 					 & \  \Jbtwo  & \  \Jctwo 	& \vline &  \Jd \\
			0 					 & \ T_{3,\perp}^T  \Jbtwo  & \ T_{3,\perp}^T  \Jctwo 	& \vline & T_{3,\perp}^T  \Jd \\
			0 					 & 0  							& \ T_{3}^T  \Jctwo 	& \vline & T_{3}^T  \Jd} \ .
		\ee
	\end{enumerate}	
		%		
\end{lemma}
\begin{proof} The first two claims followed directly from Lemma \ref{lem1.4}, while the desired matrix $\chU$
in the third part is
	%
	\[
    \chU :=
 \m{  I &\vline  &  	&		 & \vline & 	\\ \hline \\[-0.35cm]
		&\vline  & I  & 			 & \vline & 	\\
		&\vline  &    & T_{4,\perp}^T & \vline &     \\ 
		&\vline  & 	& T_{4}^T 		 & \vline &     \\ \hline \\[-0.35cm]
		&\vline  & 	&			 & \vline &  I}  
	\cdot
	\m{I &\vline &  			 & \vline & 	\\ \hline \\[-0.35cm]
		&\vline & T_{2,\perp}^T & \vline &     \\ 
		&\vline & T_{2}^T 		 & \vline &     \\ \hline \\[-0.35cm]
		&\vline & 				 & \vline &  T_{3,\perp}^T   \\ 
		&\vline & 		 		 & \vline &  T_{3}^T } 
	\cdot 
	\m{I &  \vline & \\ \hline \\[-0.35cm] & \vline & W_{1}^T \\ & \vline & W_{1,\perp}^T} 
	\cdot
	\m{T_{1,\perp}^T \\ T_1^T} \ .
	\]
	%
\end{proof}

\begin{lemma}\label{lem1.6} Let $P\in\r^{p,d}$, $Q \in \r^{q,d}$ be two full row rank matrices and $p+q\leq d$. Then, the following assertions hold true.
\begin{enumerate}
\item[i)] There exists a matrix $F\in \r^{d,d}$ such that $H := \m{P \\ QF}$ has full row rank.
\item[ii)] For any $G\in \r^{q,d}$, there exists a matrix $F\in \r^{d,d}$ such that $\m{P \\ G+QF}$ has full row rank.
\end{enumerate}	
\end{lemma}
\begin{proof}
i) First we consider the SVDs of $P$ and $G$ that reads
%
\begin{equation*}
U_P P V_P = \m{\Si_P & \ 0_{p,d-p}}, \quad U_Q Q V_Q = \m{\Si_Q & \ 0_{q,d-q}},
\end{equation*}
%
where $\Si_P$, $\Si_Q$ are nonsingular, diagonal matrices, and $0_{p,d-p}$ (resp. $0_{q,d-q}$) are the zero matrix of size $p$ by $d-p$ (resp. $q$ by $d-q$).\\
By choosing $F:= V_Q \ \m{0 & I_q \\ I_{d-q} & 0} \ V_P^{-1}$ we see that
%
\[ 
\m{U_P & 0 \\ 0 & U_Q} \ \m{P \\ QF} \ V = \m{U_P P V_P \\ U_Q QF V} = \m{\Si_P & 0_{p,d-p-q} & 0_{p,q} \\ 0_{q,p} & 0_{p,d-p-q} & \Si_Q}, \]
%
and hence, the claim i) is proven.\\
ii) Clearly, in case that the matrix $F$ is very big, then $G$ is only a small perturbation, and hence for sufficiently large $\eta$, by choosing 
%
	\[ F := \eta V_Q \ \m{0 & I_q \\ I_{d-q} & 0} \ V_P^{-1} \ , \]%
we obtain the full row rank property of $\m{P \\ G+QF}$. 
\end{proof}

\begin{remark}\label{rem1.1}
It should be noted that, the proof of Lemmata \ref{lem1.5} and \ref{lem1.6} are constructive, and all the matrices $T_{i,\perp}$, $T_{i}$, $i=1,...,4$, $W_{1,\perp}$, $W_1$ and $F$ can be stably computed.
\end{remark}
%=================================================================
%\section{Strangeness-index of high-order SiDEs}\label{Sec2}
%
%In this section, we study the analysis of high-order SiDEs of the form \eqref{eq1.1} and of the IVP \eqref{eq1.1}--\eqref{eq1.2}. First we consider a second order SiDE, i.e. $k=2$. For notational convenience, we change the notation of the matrix sequence coefficients $(A^{(k)}_n)_{n\geq n_0}$ and rewrite our SiDE as follows
%%
%\begin{equation}\label{eq2.1}
%A_{n} x(n+2) + B_{n} x(n+1) + C_{n} x(n) = f(n),\ \mbox{ for all } n \geq n_0.
%\end{equation}
%%

\section{Strangeness-index of second-order SiDEs}\label{Sec2}

In this section, we study the solvability analysis of the second-order SiDE \eqref{eq1.1} and of its corresponding IVP \eqref{eq1.1}--\eqref{eq1.2}. Many regularization procedures and their associated index concepts have been proposed for first order systems, see the survey \cite{Meh13} and the references therein. Nevertheless, for second order systems, only the strangeness-index has been proposed for only continuous time systems in \cite{MehS06,Wun08}. Thus, it is our purpose to construct a comparable index concept for system \eqref{eq1.1}. Furtheremore, we will consider some modifications in order to make the \emph{algebraic approach} more concise and better for not only theoretical analysis but also for numerical computation. 

Let
%
\begin{equation*}
M_n \!:= \m{A_{n} & B_{n} & C_{n}}, \
X_n \!:=\! \m{x(n+2) \\ x(n+1) \\ x(n)},
\end{equation*}
%
we call $\{M_n\}_{n\geq n_0}$ the \emph{behavior matrix sequence} of system  \eqref{eq1.1}. Thus,   \eqref{eq1.1} can be rewritten as
%
\begin{equation}\label{eq2.2}
M_n X_n = f(n), \mbox{ for all } n\geq n_0.
\end{equation}
%
Clearly, by scaling  \eqref{eq1.1} with a nonsingular matrix $P_n\in \r^{d,d}$, we obtain a new system
%
\begin{equation}\label{eq2.3}
\m{P_nA_{n} & P_nB_{n} & P_nC_{n}} X_n = P_n f(n), \mbox{ for all } n\geq n_0,
\end{equation}
%
without changing the solution space. This motivates the following definition.
%
\begin{definition}\label{defstrleq}	Two behavior matrix sequences $\{M_n =\m{A_{n} & B_{n} & C_{n}} \}_{n\geq n_0}$ and $\{\tM_n =\m{\tA_{n} & \tB_{n} & \tC_{n}}\}_{n\geq n_0}$ are called \emph{(strongly) left equivalent} if there exists a nonsingular matrix sequence $\{P_n\}_{n\geq n_0}$ such that $\tM_n = P_n M_n$ for all $n\geq n_0$. 
We denote this equivalence by $\{M_n\}_{n\geq n_0} \lsim \{\tM_n\}_{n\geq n_0}$.	
If this is the case, we also say that two SiDEs  \eqref{eq1.1}, \eqref{eq2.3} are left equivalent.
\end{definition}

\begin{lemma}\label{lem2.1}
Consider the behavior matrix sequence $\{M_n\}_{n\geq n_0}$ of system  \eqref{eq1.1}. Then, for all $n\geq n_0$, we have that
%
\begin{equation}\label{block-upper-M}
\{M_n\}_{n\geq n_0} \  \lsim  \ \left\{ 
	\m{A_{n,1}& B_{n,1}    & C_{n,1}     \\
	0	& B_{n,2}    & C_{n,2}     \\
	0	&    0          & C_{n,3} \\  
		0     & 0            & 0} \right\}_{n\geq n_0}, \qquad
	\pm{r_{2,n} \\ r_{1,n} \\ r_{0,n} \\ v}
	\end{equation}
where the matrices $A_{n,1}$, $B_{n,2}$, $C_{n,3}$ on the main diagonal have full row rank. Furthermore, the numbers $r_{2,n}$, $r_{1,n}$, $r_{0,n}$, $v$ are invariant under global left equivalent transformations.
Thus, we can call them the \emph{local characteristic invariants of the SiDE \eqref{eq1.1}}.
\end{lemma}
%
\begin{proof} The block diagonal form \eqref{block-upper-M} is obtained directly by consecutively compressing the block columns $A_{n}$, $B_{n}$, $C_{n}$ of $M$ via Lemma \ref{lem1.4}. From \eqref{block-upper-M}, we obtain the following identities
%
\bens
r_{2,n} &=& \rank(A_{n}), \\
r_{1,n} &=& \rank(\m{A_{n} & B_{n}}) - \rank(A_{n}), \\
r_{0,n} &=& \rank(\m{A_{n} &  B_{n} & C_{n}}) - \rank(\m{A_{n} & B_{n}}),
\eens
%
which proves the second claim.	
\end{proof}

Analogous to the continuous-time case, we will apply an \emph{algebraic approach} (see \cite{Bru09,MehS06}), which aims to reformulate   \eqref{eq1.1} into a so-called \emph{strangness-free} form, as stated in the following definition.

\begin{definition}\label{Def strangeness-free} (\cite{LinNT16})
System  \eqref{eq1.1} is called \emph{strangeness-free} if there exists a pointwise-nonsingular matrix sequence $\{P_n\}_{n\geq n_0}$ such that by scaling the SiDE  \eqref{eq1.1} at each point $n$ with $P_n$, we obtain a new system of the form
%
\be\label{def sfree}
\pm{\hr_2 \\ \hr_1 \\ \hr_0 \\\hv } \quad 
\m{\hA_{n,1} \\ 0 \\ 0 \\ 0} x(n\!+\!2) + \m{ \hB_{n,1} \\ \hB_{n,2} \\ 0 \\ 0} x(n\!+\!1) + \m{ \hC_{n,1} \\ \hC_{n,2} \\ \hC_{n,3} \\ 0} x(n)  = \m{ \hat{f}_1(n) \\  \hat{f}_2(n) \\  \hat{f}_3(n) \\ \hat{f}_4(n)}, \ \mbox{for all} \ n\geq n_0, 
\ee
%
where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank for all $n\geq n_0$. 
\end{definition}

\begin{remark}
We notice that, if the SiDE \eqref{eq1.1} is of the strangeness-free form \eqref{def sfree}, then the existence and uniqueness of the solution $\{x(n)\}_{n\geq n_0}$ can be achieved if and only if $\hr_2+\hr_1+\hr_0=d$. Furthermore, either the last block row equation of \eqref{def sfree} either do not appear , i.e. $\hv=0$, or $\hf_4(n)=0$ for all $n\geq n_0$.
\end{remark}

In order to perform an algebraic approach, an additional assumption below is usually needed.

\begin{assumption}\label{Ass1} 
Assume that the local characteristic invariants $r_{2,n}$, $r_{1,n}$, $r_{0,n}$ become global, i.e., they are constant for all $n\geq n_0$. 
\end{assumption}

Due to Lemma \ref{lem2.1}, we see that Assumption \ref{Ass1} is satisfied if and only if $\rank(A_{n})$, $\rank(\m{A_{n} & B_{n}})$, $\rank(\m{A_{n} &  B_{n} & C_{n}})$ do not depend on $n$. 
Let us call the number 
%
\[ r_u := 3 r_2 + 2 r_1 + r_0
\]
%
the \emph{upper rank} of system \eqref{eq1.2}. Clearly, $r_u$ is invariant under left equivalence transformations. Rewriting \eqref{eq2.2} block row-wise, we obtain the following system for all $n\geq n_0$.
%
\begin{subequations}\label{eq2.5}
	\begin{alignat}{3}
	\label{eq2.5a} A_{n,1} x(n+2)  + B_{n,1} x(n+1)  + C_{n,1} x(n) &= f_1(n),& \quad r_2 \ \mbox{equations}, \\
	\label{eq2.5b} B_{n,2} x(n+1)  + C_{n,2} x(n) &= f_2(n), & \quad r_1 \ \mbox{equations}, \\
	\label{eq2.5c} C_{n,3} x(n) &= f_3(n), & \quad r_0 \ \mbox{equations}, \\
	\label{eq2.5d} 0 &= f_4(n),& \quad v \ \mbox{equations}.
	\end{alignat}
\end{subequations}

Since the matrices $A_{n,1}$, $B_{n,2}$, $C_{n,3}$ have full row rank, the number of scalar difference equations of order $2$ (resp. $1$, and $0$) in  \eqref{eq1.1} is exactly $r_{2}$ (resp. $r_{1}$ and $r_{0}$), while $v$ is the number of redundant equations.

\begin{remark}
In the context of continuous-time systems, the quantities $r_2$, $r_1$, and $r_0$ are the dimensions of the second order derivative part, the first order derivative part, and the algebraic part, respectively. Furthermore, $r_2 + r_1$ is exactly the degree of freedoms of the considered system. 
\end{remark}

Now we are able to define the shift operator $\De$, which acts on some or whole equations of system \eqref{eq2.5}. This operator maps each equation of system \eqref{eq2.5} 
at the time instant $n$ to the equation itself at the time $n+1$, for example
%
\be\label{2.5c-shift} 
 \De: C_{n,3} x(n) = f_3(n) \mapsto C_{n+1,3} x(n+1) = f_3(n+1).
\ee
%
Clearly, only under Assumption \ref{Ass1}, this shift operator can be applied to equations of system \eqref{eq2.5}. 

In order to reveal all hidden constraints of \eqref{eq2.5} we propose the idea, that for each $j=1, 2$, we use difference equations of order less than $j$ to reduce the number of scalar difference equations of order $j$. This task will be performed in Lemmata \ref{lem2.9} and \ref{lem2.10} below.
In details, if the matrix pair $(B_{n,2},C_{n+1,3})$ has hidden redundancy then we will make use of 
the shifted equation \eqref{2.5c-shift}. Analogously, if the pair $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$ has hidden redundancy then we will make use of both the shifted equation
%
%\begin{equation}\label{2.5b-shift}
\[
B_{n+1,2} x(n+2)  + C_{n+1,2} x(n+1) = f_2(n+1),
\]
%\end{equation}
%
and the double shifted equation
%
%\be\label{2.5c-doubleshift} 
\[
C_{n+2,3} x(n+2) = f_3(n+2).
\]
%\ee
%
\begin{lemma}\label{lem2.0}
Consider the SiDE \eqref{eq1.1} and system \eqref{eq2.5}. Then, \eqref{eq1.1} has an identical solution set as the extended system
%
\begin{equation}\label{eq2.9}
\pm{ r_{2} \\ r_1 \\ r_0 \\ v \\ \hline  r_0 \\ r_1 \\ r_0 } \
 \m{A_{n,1}		& B_{n,1}      			   & C_{n,1} 	\\
	0 			& B_{n,2}  	   			   & C_{n,2}  	\\
	0			& 0			 			   & C_{n,3}     \\
	0 		    & 0            			   & 0 \\ \hline 
	0			& C_{n+1,3}	 			   & 0     \\
	B_{n+1,2}  	& C_{n+1,2}  			   & 0	\\
	C_{n+2,3}		& 0						   & 0     \\
} 
\m{x(n+2) \\ x(n+1) \\ x(n)}  
= \m{ f_1(n) \\ f_2(n) \\ f_3(n) \\  f_4(n) \\ \hline f_3(n+1) \\ f_2(n+1) \\  f_3(n+2) }, 
\end{equation}
for all $n\geq n_0$.
%
\end{lemma}
\begin{proof} Since all equations in the lower part of \eqref{eq2.9} at any time point $n$ is the consequence of the upper part (which is exactly \eqref{eq2.5}) at the time instants $n+1$ and $n+2$, the proof is directly followed.
\end{proof}

\begin{lemma}\label{lem2.9} Consider the behavior matrix sequence $\{M_n\}_{n\geq n_0}$ as in equation \eqref{block-upper-M}. Then, there exist matrix sequences 
$\{ S^{(i)}_{n} \}_{n\geq n_0}$, $i=1, 2$, and $\{ Z^{(j)}_{n} \}_{n\geq n_0}$, $j=1,...,5$, of appropriate sizes such that for all $n\geq n_0$, the following conditions hold true.
	\begin{enumerate}
		\item[i)] For $i=1, 2$, the matrices $\m{S^{(i)}_{n} \\ Z^{(i)}_{n}} \in \r^{r_i,r_i}$ are unitary.
		\item[ii)] The following identities hold true.
		\begin{subequations}\label{eq2.6}
			\begin{alignat}{3}
			\label{eq2.6a} Z^{(1)}_{n} B_{n,2} + Z^{(3)}_{n} C_{n+1,3} &=& 0, \\
			\label{eq2.6b} Z^{(2)}_{n} A_{n,1} + Z^{(4)}_{n} B_{n+1,2} + Z^{(5)}_{n} C_{n+2,3} & = & 0.
			\end{alignat}	
		\end{subequations}	
		\item[iii)] Both matrix pairs $\left(S^{(2)}_{n} A_n, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$, $\left(S^{(1)}_{n} B_{n,2},C_{n+1,3}\right)$ have no hidden redundancy. 
	\end{enumerate}
	%
\end{lemma}
\begin{proof}
The proof can be directly obtained by applying Lemma \ref{lem1.2} to two matrix pairs $(B_{n,2},C_{n+1,3})$ and $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$.
\end{proof}

For $i=1$, $2$, let us denote the row dimensions of $S^{(i)}_n$ and $Z^{(2)}_{n}$ by $d_i$ and $s_i$, respectively. For notational convenience, we set 
\begin{align}\label{eq2.11}
\begin{split}
K_{n,1}  &:=Z^{(2)}_{n} B_{n,1} + Z^{(4)}_{n} C_{n+1,2}, \quad H_{n,1}:=Z^{(2)}_{n} C_{n,1}, \\
\ga(n+2) &:=Z^{(2)}_{n} f_1(n)  + Z^{(4)}_{n} f_2(n+1) + Z^{(5)}_{n} f_3(n+2).
\end{split}
\end{align}

\begin{lemma}\label{lem2.10}
Consider the matrix sequences  $\{ Z^{(j)}_{n} \}_{n\geq n_0}$, $j=1,...,5$ as in Lemma \ref{lem2.1}. Then, there exist a unitary matrix  $\m{S^{(6)}_{n} \\ Z^{(6)}_{n}} \in \r^{s_2,s_2}$ and a matrix $Z^{(7)}_{n}$ of appropriate size, such that the pair $(S^{(6)}_{n}, C_{n+1,3})$ has no hidden redundancy and 
%
\be\label{eq2.12}
Z^{(6)}_{n} K_{n,1} + Z^{(7)}_{n} C_{n+1,3} = 0 \ .
\ee
%
\end{lemma}
\begin{proof}
The proof is directly followed by applying Lemma \ref{lem1.2} to the matrix pair $(K_{n,1},C_{n+1,3})$.
\end{proof}

\begin{theorem}\label{thm2} Consider the behavior matrix sequence $\{M_n\}_{n\geq n_0}$ in \eqref{block-upper-M}. Let the matrix sequences $\{ S^{(i)}_{n} \}_{n\geq n_0}$, $i=1, 2$ and $\{ Z^{(j)}_{n} \}_{n\geq n_0}$, $j=1,...,5$, be defined as in Lemmata \ref{lem2.9} and \ref{lem2.10}. Let the matrices $K_{n,1}$, $H_{n,1}$ and the function $\gamma(n+2)$ be defined as in \eqref{eq2.11}. Then, the SiDE \eqref{eq1.2} has exactly the same solution set as the following system
%
\begin{equation}\label{eq2.13}
\pm{ d_{2} \\ s_{21} \\ s_{20} \\ \hline \\[-0.35cm] d_1 \\ s_1 \\ \hline \\[-0.35cm] r_0 \\ v} \
\m{ S^{(2)}_{n} A_{n,1} & S^{(2)}_{n} B_{n,1}      	   & S^{(2)}_{n} C_{n,1} 	\\
	0					& S^{(6)}_{n} K_{n,1}  	       & S^{(6)}_{n} H_{n,1}  	\\
	0					& 0			  				   & Z^{(6)}_{n} H_{n,1}    \\ \hline \\[-0.35cm]
	0 					& S^{(1)}_{n} B_{n,2}  	   	   & S^{(1)}_{n} C_{n,2}    \\
	0 					& 0                			   & Z^{(1)}_{n} C_{n,2} 	\\ \hline \\[-0.35cm]
	0					& 0				 			   & C_{n,3}     \\
	0 		    		& 0              			   & 0 
} 
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} 
\!=\! 
\m{ S^{(2)}_{n} f_1(n) \\ 
	S^{(6)}_{n} \ga(n\!+\!2)     \\ 
	Z^{(6)}_{n} \ga(n\!+\!2) \!+\! Z^{(7)}_{n} f_3(n\!+\!1)    \\ \hline \\[-0.35cm] 
	S^{(1)}_{n} f_2(n) \\ 
	Z^{(1)}_{n} f_2(n) \!+\! Z^{(3)}_{n} f_3(n\!+\!1)    \\ \hline 
	f_3(n)             \\  
	f_4(n)
},
\end{equation}
%		
for all $n\geq 0$. Here we have $r_2 = d_2 + s_2$, $r_1=d_1+s_1$, $s_2 = s_{21}+s_{20}$. Furthermore, both matrix pairs $\left(S^{(2)}_{n} A_n, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$ and, $\left( \m{S^{(6)}_{n} \tK_{n,1} \\ S^{(1)}_{n} B_{n,2}},C_{n+1,3}\right)$ have no hidden redundancy.                                                                                                                       
\end{theorem}                       
\begin{proof}
The main idea of this proof is to apply elementary row transformations to system \eqref{eq2.9} to obtain \eqref{eq2.13}. Since the proof is quite long and technical, we present it in Appendix \ref{App1}.
\end{proof}

\begin{remark} From \eqref{eq2.11}, we notice that if the pair $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$ has hidden redundancy, then $Z^{(2)}_n$ is not an empty matrix. 
Furthermore, if $Z^{(5)}_n$ is also not an empty matrix, then we need two shifts to pass from \eqref{eq2.5} to \eqref{eq2.13}. 
\end{remark}
%
Comparing system \eqref{eq2.13} with \eqref{eq2.5}, we see that the number of second, first and zero-order difference equations are $d_2$, $s_{21}+d_1$, and $s_{20}+s_1+r_0$, respectively. The upper rank of this modified system is
%
\[
r_u^{new} \leq 3 d_2 + 2 (s_{21} + d_1) + (s_{20} + s_1 + r_0) =  r- (s_{21}+2s_{20}+s_1) \leq r.
\]
%
In conclusion, after performing this \emph{index reduction step}, which passes from \eqref{eq2.5} to \eqref{eq2.13}, we have reduced the upper rank $r_u$ at least by $s_{21}+2s_{20}+s_1$. 
Continuing in this way until $s_{21}= s_{20} = s_1=0$, we obtain the following algorithm.
%
\begin{algorithm}[H]
	\caption{Index reduction steps for SiDEs at the time point $n$}
	\label{Alg1}
	\begin{algorithmic}[1]
		\State \textbf{Input:} The SiDE  \eqref{eq1.1} and its behavior form \eqref{eq2.2}. Set $i=0$, $\mu=0$.
		\State \textbf{Return:} The resulting system in a special form.
		%
%		\algstore{myalg}
%		\end{algorithmic}
%		\end{algorithm}	
%		\begin{algorithm}[H]
%		\begin{algorithmic}[1]
%		\algrestore{myalg}
		%
		\State Transform the behavior matrix $\m{A_n & B_n & C_n}$ to the block upper triangular form
		%
		\[\tM :=
		\begin{bmatrix}
		A_{n,1} & B_{n,1}  & C_{n,1}     \\
		0       & B_{n,2}  & C_{n,2}      \\
		0       & 0        & C_{n,3}  \\ 
		0       & 0        & 0
		\end{bmatrix}, \quad
		\begin{matrix}{r_2}\\
		{r_1}\\
		{r_{0}}\\  
		{v}
		\end{matrix}
		\]
		where all the matrices $A_{n,1}$, $B_{n,2}$, $C_{n,3}$ on the main diagonal have full row rank.
		\IF{both matrix pairs $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}}\right)$ and $\left(B_{n,2},C_{n+1,3} \right)$ have no hidden redundancy} STOP. 
		%
		\ELSE{ set $i := i + 1$ and go to 6} 
		%
		\State Find the matrices $S^{(i)}_{n}$, $i=1, 2$, and $Z^{(j)}_{n}$, $j=1,...,5$ as in Lemma \ref{lem2.9}. 				
		%
		\IF{$Z^{(5)}_n \not= [ \ ]$} set $\mu :=\mu+2$. 
		%
		%\ELSIF{$Z^{(5)}_n = [ \ ]$ and $Z^{(2)}_n \not= [ \ ]$} set $\mu :=\mu+1$. 
		%
		\ELSE{ set $\mu :=\mu+1$}
		%
		\ENDIF
		%
		\State Compute the matrices $K_{n,1}$, $H_{n,1}$ as in \eqref{eq2.11} 
		%
		\IF{the matrix pair $\left( K_{n,1}, C_{n+1,3} \right)$ has no hidden redundancy} go to 14. 
		%
		\ELSE{ find the matrices $S^{(6)}_{n}$, $Z^{(6)}_{n}$, $Z^{(7)}_{n}$ as in Lemma \ref{lem2.10}}. 				
		%
		\ENDIF
		\State Transform system \eqref{eq2.5} to system \eqref{eq2.13} as in Theorem \ref{thm2}.
		%
		\ENDIF
		\State Go back to 3.		
	\end{algorithmic}
\end{algorithm}

After each index reduction step the upper rank $r^{i}_u$ has been decreased at least by $s^{i}_2+s^{i}_1$, so Algorithm \ref{Alg1} terminates after a finite number $\mu$ of iterations, which will be called the \emph{strangeness-index} of the SiDE  \eqref{eq1.1}.

\begin{theorem}\label{thm3} Consider the SiDE \eqref{eq2.2} and assume that Assumption \ref{Ass1} is satisfied for any $n$ and any considered $i$ in the loop. 
Then, the SiDE  \eqref{eq1.1} has the same solution set as the strangeness-free-SiDE
	%
	\be\label{sfree-SiDE}
	\pm{r^{\mu}_{2} \\ r^{\mu}_{1} \\ r^{\mu}_{0} \\ v^{\mu}} \qquad
	\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
		0		& \hB_{n,2}    & \hC_{n,2}     \\
		0		&    0          & \hC_{n,3} \\ 
		0       & 0          & 0}
	\m{x(n+2) \\ x(n+1) \\ x(n)} = \m{ \hg_1(n) \\  \hg_2(n) \\  \hg_3(n) \\ \hg_4(n)}, \ \mbox{for all} \ n\geq n_0, 
	\ee
	%
	where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank for all $n\geq n_0$. Here $\hg_2$ and $\hg_3$, are functions of $f(n+1),\dots,f(n+\mu)$.
\end{theorem}
%
\begin{proof}
The proof is a direct consequence of Algorithm \ref{Alg1}, where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank due to Lemma \ref{lem1.3}.
%Clearly, after carrying out Algorithm \ref{Alg1}, we obtain a system of the form \eqref{sfree-SiDE}, where
%the matrices $\hA_{n,1}$, $\hB_{n,2}$, $\hC_{n,3}$ have full row rank and none of the matrix pairs 
%$\left(\hA_{n,1},\m{\hB_{n+1,2} \\ \hC_{n+2,3}}\right)$, $(\hB_{n+1,2},\hC_{n+2,3})$ has a hidden redundancy.
%Lemma \ref{lem1.3} applied to three matrices $\hA_{n,1}$, $\hB_{n+1,2}$ and $\hC_{n+2,3}$, therefore, straightly implies the second claim of this theorem.
\end{proof}

To illustrate Algorithm \ref{Alg1}, we consider the following example.

\begin{example}
Consider the second order SiDE
\be\label{eq2.14}
\m{ 1 & \ n\!\!+\!\!1 & \ n\!\!+\!\!4 \\  0 & 0 & 0 \\ 0 & 0 & 0} x(n\!+\!2) \!+\!
\m{ 0 \ & 0 & 2n\!+\!3 \\ 1 \ & n & 1 \\  0 \ & 0 & 0} x(n\!+\!1) \!+\!
\m{ 0 & n\!+\!1 & 0 \\ 0 & 0 & n \\  0 & 0 & n\!+\!1} x(n) \!=\! \m{f_{1}(n) \\ f_{2}(n) \\ f_{3}(n)}, 
\ee
%
for all $n\geq n_0=0$. Fortunately, the behavior matrix 
%
\[
M \!=\! 
\left[
\begin{tabular}{ccc|ccc|ccc}
1 & \ n\!+\!1   & n\!+\!4 	& 0   & 0 & 2n+3 & 0 & n+1 	& 0 \\  \hline 
0 & 0 			& 0 		& 1 \ & n & 1 	 & 0 & 0	 	& n \\ \hline 
0 & 0 			& 0 		& 0 \ & 0 & 0 	 & 0 & 0	 	& n+1
\end{tabular} 
\right]
\!=\! \m{	A_{n,1} & B_{n,1}  & C_{n,1}     \\
		0       & B_{n,2}  & C_{n,2}      \\
		0       & 0        & C_{n,3} 
	}
\]
%
is already in the block diagonal form, so we do not need to perform Step 3 in Algorithm \ref{Alg1}. Furthermore, all constant rank conditions required in Assumption \ref{Ass1} are satisfied. 
We observe here that 
%
\begin{align*}
B_{n+1,2} &= \m{1 \ & \ n+1 & \ 1}, \quad C_{n+1,2} = \m{0 \ & \ 0	& \ n+1}, \\
C_{n+1,3} &= \m{0 \ & \ 0	& \ n+2}, \quad C_{n+2,3} = \m{0 \ & \ 0	& \ n+3}. 
\end{align*}
%
By directly verifying, we see that the matrix pair $\left(A_{n,1}, \m{B_{n+1,2} \\ C_{n,3} } \right)$ has hidden redundancy, while the pair $(B_{n,2},C_{n+1,3})$ does not. 
Due to Lemma \ref{lem2.9} we choose $S^{(2)}_{n} = [ \ ]$, $Z^{(2)}_{n}=1$, $Z^{(4)}_{n}=-1$, $Z^{(5)}_{n}=-1$. 
Notice, that $Z^{(5)}_{n}$ is non-empty, so this results in the appearance of $f_3(n+2)$ in the function $\ga$ of \eqref{eq2.11}. In details, we have that
%
\begin{align*}
\begin{split}
K_{n,1}  &= \m{0   & 0	& n+2}, \quad H_{n,1}=\m{0   & n+3	& 0}, \\
\ga(n+2) &= f_1(n)  - f_2(n+1) - f_3(n+2).
\end{split}
\end{align*}
%
Here, we observe that the pair ($K_{n,1},C_{n+1,3}$) has hidden redundancy. Due to Lemma \ref{lem2.10} we choose $S^{(6)}_{n} = [ \ ]$, $Z^{(6)}_{n}=1$, $Z^{(7)}_{n}=-1$.
Therefore, system \eqref{eq2.13} reads
%
\begin{align*}
& \m{ 0 & 0 & 0 \\  0 & 0 & 0 \\ 0 & 0 & 0} x(n+2) +
\m{ 0 \ & 0 & 0 \\ 1 \ & n & 1 \\  0 \ & 0 & 0} x(n+1) +
\m{ 0 & n+1 & 0 \\ 0 & 0 & n \\  0 & 0 & n+1} x(n) \\
& = \m{f_{1}(n) - f_2(n+1) - f_3(n+2) - f_3(n+1) \\ f_{2}(n) \\ f_{3}(n)}. 
\end{align*}
%
Go back to Step 3, we obtain the following system
%
\begin{align*}
& \m{ 1 \ & n & 1 \\ \hline  0 \ & 0 & 0 \\ 0 & 0 & 0} x(n+1) + \m{ 0 & 0 & n \\ \hline  0 & n+1 & 0 \\ 0 & 0 & n+1} x(n) \\
& = \m{f_{2}(n) \\ \hline f_{1}(n) - f_2(n+1) - f_3(n+2) - f_3(n+1) \\ f_{3}(n)}. 
\end{align*}
%
Algorithm \ref{Alg1} terminates here, and the strangeness-index is $\mu=2$, which is exactly the number of time-shift applied to the inhomogeneity $f$ in order to obtain the strangeness-free formulation.
\end{example}

A direct consquence of Theorem \ref{thm3} is, that we can deduce the theoretical solvability for \eqref{eq1.1} as follows.

\begin{corollary}\label{Cor1} Consider the SiDE \eqref{eq1.1} and assume that Assumption \ref{Ass1} is satisfied for any $n$ and any considered $i$ in the loop, such that the strangeness-index $\mu$ exists. Then the following statements hold.
	\begin{enumerate}
		\item[i)] The corresponding IVP for the SiDE \eqref{eq1.1} is solvable if and only if $\hg_4(n)\!=\!0$ for all $n\geq n_0$. Furthermore, it is uniquely solvable if, in addition, we have $r^{\mu}_{2} + r^{\mu}_{1} + r^{\mu}_{0} = d$.
		\item[ii)] The initial condition $x_0=x(n_0)$ is consistent if and only if the following equalities hold.
		%
		\bens 
		\hB_{n_0,2}x_1 + \hC_{n_0,2} x_0 &=& \hg_2(n_0), \\
		\hC_{n_0,3}x_0 &=& \hg_3(n_0).
		\eens 
		% 
	\end{enumerate}	
\end{corollary}

Another direct consequence of Theorem \ref{pro3.1} is, that we can obtain an underlying difference equation as follows.
%
\begin{corollary}\label{Cor2}
	Consider the SiDE \eqref{eq1.1} and assume that the corresponding IVP is uniquely solvable. Moreover, suppose that Assumption \ref{Ass1} is satisfied for any $n$ and any considered $i$ in the loop, such that the strangeness-index $\mu$ exists. 
	Then the solution to this IVP is also the solution of the \emph{(implicit) underlying difference equation}
	%
	\be\label{underlying}
	\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}  x(n+2) + \m{ \hB_{n,1}  \\ \hC_{n+1,2} \\ 0} x(n+1) + \m{\hC_{n,1} \\ 0 \\ 0}	x(n) = \m{ \hg_1(n) \\  \hg_2(n+1) \\  \hg_3(n+2)},
	\ee
	%
	where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ is invertible for all $n\geq n_0$.	
\end{corollary}
%
\begin{remark} 
	i) Within one loop of Algorithm \ref{Alg1}, for each $n$, we have used 4 SVDs to remove the hidden redundancies in two matrix pairs. The total cost depends on the problems itself, i. e., depending on sizes of the matrix pairs which applied SVDs. Nevertheless, the total cost would not exceed ${\cal O}(m^2 d^2)$.\\
	ii) Different from \cite{MehS06} (see Remark 17), due to Step 7 in Algorithm \ref{Alg1}, $\mu$ is the exact number of shifts that have been used in order to achieve \eqref{sfree-SiDE}. \\
	%Consequently, $x(n)$ depends on $f(n+1),\dots,f(n+\mu)$ but not $\{f(n+\mu+k)\}_{k\geq 1}$. \\ 
	iii) Unfortunately, since $Z_2$ is not orthogonal, Algorithm \ref{Alg1} could not be stably implemented. For the numerical solution to the IVP \eqref{eq1.1}-\eqref{eq1.2}, we will consider a suitable numerical scheme in Section \ref{Sec3}. \\
	iv) Unlike in \cite{LosM08,MehS06}, we do not change the variable $x$. This trick permits us to simplify significantly the condensed form in \cite{Bru09,MehS06}. This trick is also useful for the control analysis of the descriptor system \eqref{eq1.0} as will be seen later. % in Section \ref{Sec4}.	
\end{remark}

%=================================================================
\section{Strangeness-index of second order descriptor systems}\label{Sec2b}

Based on the index reduction procedure for SiDEs in Section \ref{Sec2}, in this section we construct the strangeness-index concept for the descriptor system \eqref{eq1.0}.
%%
%\begin{equation}\label{eq5.1}
%A_{n} x(n+2) + B_{n} x(n+1) + C_{n} x(n) + D_{n} u(n)= f(n),\ \mbox{ for all } n \geq n_0.
%\end{equation}
%%
%Here the matrix sequence $\{ D_{n} \}_{n\geq n_0}$ take values in $\r^{m,p}$ and $u(n) \in \r^{p}$ for all $n\geq n_0$. 
The solvability analysis for first order descriptor systems with variable coefficients have been carefully discussed in \cite{KunMR01,Rat97,ByeKM97}. Nevertheless, for second order descriptor systems, this problem has been rarely considered. We refer the interested readers to \cite{LosM08,Wun08} for continuous time systems. 

In the index reduction procedure of continuous time systems, one should avoid differentiating equations that involve an input function, due to the fact that it may not be differentiable. Here, we will also keep this spirit, and hence, will not shift any equation that involve an input function, since it may destroy the causality of the considered system. In the following lemma, we give the condensed form for system \eqref{eq1.0}.

\begin{lemma}\label{lem5.1} Consider the descriptor system \eqref{eq1.0}. Then, there exist two pointwise nonsingular matrix sequences $\{U_n\}_{n\geq n_0}$, $\{V_n\}_{n\geq n_0}$ such that the following identities hold.
	%
	\begin{align}\label{eq5.2}	
  &	(U_n \m{A_{n} & B_{n} & C_{n}}, \ U_n D_n V_n)  \notag \\ 
  &= \left( \m{A_{n,1}  & B_{n,1}    & C_{n,1}     \\
		0    & B_{n,2}    & C_{n,2}     \\
		0    & 0          & C_{n,3}     \\  \hline
		0    & B_{n,4}    & C_{n,4}     \\
		0    & 0          & C_{n,5}     \\  
		0    & 0          & 0}, \
	\m{ D_{n,11} 		& 0			& 0		  \\
		0 			& 0		    & 0		  \\
		0 			& 0		    & 0        \\	\hline 
		0      	    & \Si_{\vphi,1} 	    & 0 		 \\ 
		0     		& 0		    & \Si_{\vphi,0}       \\
		0     		& 0         & 0 } \right), \quad 
	\pm{r_{2,n} \\ r_{1,n} \\ r_{0,n} \\ \vphi_{1,n} \\ \vphi_{0,n} \\  v_n} \quad 
	\mbox{ for all } n\geq n_0.
	\end{align}	
	Here sizes of the block rows are $r_{2,n}$, $r_{1,n}$, $r_{0,n}$, $\vphi_{1,n}$, $\vphi_{0,n}$, $v_n$, the matrices $A_{n,1}$, $B_{n,2}$, $B_{n,4}$, $C_{n,3}$ are of full row rank and the matrices $\Si_{\vphi,1}$, $\Si_{\vphi,0}$ are nonsingular and diagonal.
\end{lemma}

\begin{proof}
First we apply Lemma \ref{lem1.5} to four matrices $A_n$, $B_n$, $C_n$ and $D_n$ to obtain the matrix $U_n$ that satisfies \eqref{eq1.10}. Decompose the matrix $\m{T_{3,\perp}^T \\  T_{3}^T}  \Jd$ via one SVD, we then obtain the block 
%
$ \m{
	0      	    & \Si_{\vphi,1} 	    & 0 		 \\ 
	0     		& 0		    & \Si_{\vphi,0} } \ .
$
%
Finally, we use Gaussian elimination to cancel out all matrices on the two columns of $\chD$ that contain $\Si_{\vphi,1}$ and $\Si_{\vphi,0}$, and hence, we obtain the desired form \eqref{eq5.2}.
\end{proof}

In order to build an index reduction procedure for \eqref{eq1.0}, we also need the following assumption.
%
\begin{assumption}\label{Ass2}
Assume that the local characteristic invariants $r_{2,n}$, $r_{1,n}$, $r_{0,n}$, $\vphi_{1,n}$, $\vphi_{0,n}$, $v_n$, become global, i.e., they are constant for all $n\geq n_0$. 
\end{assumption}
%

Applying Lemma \ref{lem5.1}, we can transform the descriptor system \eqref{eq1.0} to the following system
%
\begin{equation}\label{eq5.3}
\pm{r_{2} \\ r_{1} \\ r_{0} \\ \vphi_{1} \\ \vphi_{0} \\  v} \
\m{A_{n,1}  & B_{n,1}    & C_{n,1}     \\
	0    	& B_{n,2}    & C_{n,2}     \\
	0    	& 0          & C_{n,3}     \\  \hline
	0    	& B_{n,4}    & C_{n,4}     \\
	0    	& 0          & C_{n,5}     \\  
	0    	& 0          & 0} 
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) } \!+\! 
\m{ D_{n,11} 	    & 0		    & 0		  \\
	0 	    & 0		    & 0		  \\
	0 	    & 0		    & 0        \\	\hline 
	0      	    & \Si_{\vphi,1} & 0 		 \\ 
	0     	    & 0		    & \Si_{\vphi,0}       \\
	0     	    & 0             & 0 } \m{v_1(n) \\ v_2(n) \\ v_3(n)} \!=\! \tf(n),
\end{equation}
%
where $u(n) = V_n v(n)$, $v(n) := \m{v_1(n) \\ v_2(n) \\ v_3(n)}$, $\tf(n):=U_nf(n)$ for all $n\geq n_0$.\\

In this decomposition, we notice that the third and fourth block rows, whose sizes are $\vphi_1$ and $\vphi_0$, are related to the feedback regularization of \eqref{eq1.0}, as shown in the following proposition.

\begin{proposition}\label{pro5.1}
i)	Assume that for each $n\geq n_0$, the matrix $\m{A_{n,1} \\ B_{n+1,2} \\ C_{n+2,3}}$ is of full row rank.
Then, there exist two matrices $F_{n,1}$ and $F_{n,0}$ such that the following matrix has full row rank
%
\[
\m{ A_{n,1} \\ B_{n+1,2} \\ C_{n+2,3} \\ B_{n+1,4} + \m{0 & \Si_{\vphi,1} & 0} F_{n,1} \\ C_{n+2,5} + \m{0 & 0 & \Si_{\vphi,0}} F_{n,0} }.
\]
%
ii) Consequently, if the upper part of \eqref{eq5.3} is strangeness-free then there exists a first order feedback of the form
%
\be\label{eq5.5}
u(n) = F_{n,1} x(n+1) + F_{n,0} x(n), \mbox{ for all } n\geq n_0,
\ee
%	
such that the closed loop system associated with \eqref{eq3.3} is strangeness-free.	
\end{proposition}
\begin{proof}
Since the part ii) is a direct consequence of part i), we only need to prove i). The part i) is directly followed from Lemma \ref{lem1.6} with $P=\m{ A_{n,1} \\ B_{n+1,2} \\ C_{n+2,3}}$, $Q=\m{0 & \Si_{\vphi,1} & 0  \\ 0 & 0 & \Si_{\vphi,0} }$ and $G=\m{B_{n+1,4} \\ C_{n+2,5}}$.
\end{proof}

%Proposition \ref{pro5.1} motivates the following definition.
%\begin{definition}
%content
%\end{definition}
From Proposition \ref{pro5.1}, we see that we only need to remove the hidden redundancies in the upper part of 
\eqref{eq5.3}. This will be done as in the following lemma.

\begin{lemma}\label{lem5.2}
Consider the descriptor system \eqref{eq5.3}. Then, for each input sequence $\{v(n)\}_{n\geq n_0}$, it has exactly the same solution set as the following system
%
\begin{equation}\label{eq5.4}
\pm{\tr_{2} \\ \tr_{1} \\ \tr_{0} \\ \vphi_{1} \\ \vphi_{0} \\  v} \
\m{\tA_{n,1}    & \tB_{n,1}    & \tC_{n,1}     \\
	0    		& \tB_{n,2}    & \tC_{n,2}     \\
	0    		& 0            & \tC_{n,3}     \\  \hline
	0    		& B_{n,4}      & C_{n,4}     \\
	0    		& 0            & C_{n,5}     \\  
	0    		& 0            & 0} 
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) } \!+\! 
\m{ \tD_{n,11} 	& 0			& 0		  \\
	0	 		& 0		    & 0		  \\
	0 			& 0		    & 0        \\	\hline 
	0      	    & \Si_{\vphi,1} 	    & 0 		 \\ 
	0     		& 0		    & \Si_{\vphi,0}       \\
	0     		& 0         & 0 } \m{v_1(n) \\ v_2(n) \\ v_3(n)} \!=\! \tf(n),
\end{equation}
%
where $\tr_2<r_2$, $\tr_0>r_0$, $\sum_{i=0}^{2}r_i = \sum_{i=0}^{2}\tr_i$.
\end{lemma}
\begin{proof}
System \eqref{eq5.4} is directly obtained by applying Theorem \ref{thm2} to the upper part of \eqref{eq5.3}. To keep the brevity of this paper, we will omit the details here.
\end{proof}

Similar to the observation made in Section \ref{Sec2}, here we also see, that the so-called \emph{index reduction step}, which passes system \eqref{eq5.3} to the new form \eqref{eq5.4} 
has reduced the upper rank $r^u$ by at least $(\tr_0-r_0)+(r_2-\tr_2)$. Continuing in this way, finally we obtain the strangeness-free descriptor system in the next theorem.

\begin{theorem}\label{thm5.1}
Consider the descriptor system \eqref{eq1.0}. Furthermore, assume that Assumption \ref{Ass2} is fulfilled whenever needed. Then, for each fixed input sequence $\{u(n)\}_{n\geq n_0}$, system \eqref{eq1.0} has the same solution set as the so-called \emph{strangness-free descriptor system} 
%
\be\label{sfree-descriptor}
\pm{\hr_{2} \\ \hr_{1} \\ \hr_{0} \\ \\[-0.35cm] \hat{\vphi}_{1} \\ \hat{\vphi}_{0} \\  \hv} \ 
\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
	0		& \hB_{n,2}    & \hC_{n,2}     \\
	0		&    0          & \hC_{n,3}		 \\ \hline \\[-0.35cm]
	0    & \hB_{n,5}    & \hC_{n,5}     \\
	0    & 0          & \hC_{n,6}     \\ 
	0    & 0          & 0} \!
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} \!+\! 
\m{\hD_{n,1} \\ 0 \\ 0  \\ \hline \\[-0.35cm] \hD_{n,4} \\ \hD_{n,5} \\ 0} \! u(n) 
\!=\! \m{\hf_1(n) \\ \hf_2(n) \\ \hf_3(n) \\ \hline \\[-0.35cm] \hf_4(n) \\ \hf_5(n) \\ \hf_6(n) }, \mbox{ for all } n\geq n_0,
\ee
%
where the matrices $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$, $\m{\hD_{n,4} \\ \hD_{n,5}}$ have full row rank for all $n\geq n_0$. 
%
\end{theorem}
\begin{proof}
By performing index reduction steps until the upper rank $r^u$ stop decreasing, we obtain the system 
%
\begin{equation*}
\pm{\hr_{2} \\ \hr_{1} \\ \hr_{0} \\ \\[-0.35cm] \hat{\vphi}_{1} \\ \hat{\vphi}_{0} \\  \hv} \quad
\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
	0		& \hB_{n,2}    & \hC_{n,2}     \\
	0		&    0          & \hC_{n,3}		 \\ \hline \\[-0.35cm]
	0       & \hB_{n,5}    & \hC_{n,5}     \\
	0    	& 0          & \hC_{n,6}     \\ 
	0    	& 0          & 0}
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} \!+\! 
\m{\hD_{n,11}		& 0			& 0		  \\
	0 			& 0		    & 0		  \\
	0 			& 0		    & 0        \\	\hline 
	0      	& \Si_{\hat{\vphi}_{1}} & 0			 \\ 
	0     		& 0		    & \Si_{\hat{\vphi}_{0}}        \\ 
	0     		& 0         & 0       	
} v(n) \!=\! \m{\hf_1(n) \\ \hf_2(n) \\ \hf_3(n) \\ \hline \\[-0.35cm] \hf_4(n) \\ \hf_5(n) \\ \hf_6(n) }, 
\end{equation*}
%
for all $n\geq n_0$, where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank for all $n\geq n_0$. Here the new input sequence $\{v(n)\}_{n\geq n_0}$ satisfies $u(n)=V_nv(n)$, $V_n$ is nonsingular for all $n\geq n_0$. Transform back $v(n) = V^{-1}_n u(n)$, and set
%
\[ 
\m{\hD_{n,1} \\ 0 \\ 0 \\ \hline \\[-0.35cm] \hD_{n,4} \\ \hD_{n,5} \\ 0} :=
\m{\hD_{n,11}		& 0			& 0		  \\
	0 			& 0		    & 0		  \\
	0 			& 0		    & 0        \\	\hline 
	0      	& \Si_{\hat{\vphi}_{1}} & 0			 \\ 
	0     		& 0		    & \Si_{\hat{\vphi}_{0}}        \\ 
	0     		& 0         & 0       	
} V^{-1}, 
\]
%
we obtain exactly the strangeness-free descriptor system \eqref{sfree-descriptor}.
\end{proof}

As a direct corollary of Theorem \ref{thm5.1}, we obtain the existence and uniqueness of a solution to the closed-loop system via feedback as follows.

\begin{corollary}\label{coro5.1}
Consider the descriptor system \eqref{eq1.0}. Furthermore, assume that Assumption \ref{Ass2} is fulfilled whenever needed, so that the strangeness-free descriptor system \eqref{sfree-descriptor} is well-defined. 
Then, the following statements hold true.\\
i) There exists a first order feedback of the form \eqref{eq5.5} such that the closed-loop system is solvable if and only if $\hf_6(n)=0$ for all $n\geq n_0$. \\
ii) Furthermore, the solution to the corresponding IVP (of the closed-loop system) is unique if and only if in addition, $d=\sum_{i=0}^{2}\hr_i + \sum_{i=0}^{1}\hat{\vphi}_i$.
\end{corollary}

\begin{remark}
It should be noted that, in analogous to SiDEs, each index reduction step of the descriptor system \eqref{eq1.0} makes use of Theorem \ref{thm2}, where the matrices $Z^{(i)}_n$, $i=3,4,5$, may not be orthogonal. Furthermore, in Lemma \ref{lem5.1}, two matrices $U_n$, $V_n$ are only nonsingular but not orthogonal. 
Therefore, in general, the strangeness-free formulation \eqref{sfree-descriptor} could not be stably computed. For the numerical treatment of (continuous time) second order DAEs, in \cite{Wun08} a different approach was developed. We will modify it for handling SiDEs and descriptor systems in the next section.
\end{remark}
%=================================================================
\section{Difference arrays of second-order SiDEs/descriptor systems}\label{Sec3}

As have shown in two previous sections, to analyze the theoretical solvability of the SiDE  \eqref{eq1.1}
or of the descriptor system \eqref{eq1.0}, first one needs to bring it to a strangeness-free formulation. 
Nevertheless, this task is not always doable, for example when Assumptions \ref{Ass1}, \ref{Ass2} are violated at some index reduction steps. These difficulties have also been observed for continuous time systems of both first and higher orders, and they have been addressed in \cite{KunMR01,Wun08}.
The basic idea, thanks to Campbell \cite{Cam87}, while considering DAEs, is to differentiate a given system a number of times and put every one of them, including the original one, into a so-called \emph{an inflated system}. Then, the strangeness-free formulation will be determined by appropriate selection of equations inside this inflated system. In this section we will examine this approach to the descriptor system \eqref{eq1.0}. The analysis for SiDEs of the form \eqref{eq1.1} can be obtained by simply setting an input $u$ to be $0$.
%Furthermore, we assume that for each fixed input sequence $\{u(n)\}_{n\geq n_0}$ the corresponding IVP to system \eqref{eq1.0} is uniquely solvable. 
We further assume the following condition.

\begin{assumption}\label{Ass3}
Consider the descriptor system \eqref{eq1.0}. Assume that there exists a first order feedback of the form \eqref{eq5.5} such that the closed-loop system is uniquely solvable.
\end{assumption}
It should be noted that, in case of the SiDE \eqref{eq1.1}, Assumption \ref{Ass3} means that the corresponding IVP \eqref{eq1.1}-\eqref{eq1.2} is uniquely solvable.
Now let us introduce the \emph{difference-inflated system of level $\ell \in \N$} as follows.
%
\bens
A_{n} x(n\!+ \!2) \!+ \! B_{n} x(n\!+ \!1) \!+ \! C_{n} x(n) \!+ \! D_n u(n) &\!=\!& f(n), \notag \\
A_{n\!+ \!1} x(n\!+ \!3) \!+ \! B_{n\!+ \!1} x(n\!+ \!2) \!+ \! C_{n\!+ \!1} x(n\!+ \!1) \!+ \! D_{n\!+ \!1} u(n\!+ \!1) &\!=\!& f(n\!+ \!1), \notag	\\
&\dots& \\
%A_{n\!+\!\ell\!-\!1} x(n\!+\!\ell\!+\!1) \!+\! B_{n\!+\!\ell\!-\!1} x(n\!+\!\ell) \!+\! C_{n\!+\!\ell\!-\!1} x(n\!+\!\ell\!-\!1) &\!=\!& f(n\!+\!\ell\!-\!1), \notag \\
A_{n\!+\!\ell} x(n\!+\!\ell\!+\!2) \!+\! B_{n\!+\!\ell} x(n\!+\!\ell\!+\!1) \!+\! C_{n\!+\!\ell} x(n\!+\!\ell) \!+\! D_{n\!+\!\ell} u(n\!+\!\ell) &\!=\!& f(n\!+\!\ell) \ . \notag
\eens
%
We rewrite this system as
%
%\[
%\underbrace{\m{
%		C_n	& B_n     & A_n     &         &         &  &  &  \\ 
%		& C_{n\!+\!1} & B_{n\!+\!1} & A_{n\!+\!1} &         &  &  &  \\ 
%		&         & \ddots  & \ddots  & \ddots  &  &  &  \\ 
%		&         &         & \ddots  & \ddots  & \ddots &  &  \\ 
%		%		&         &         &         & \ddots  & \ddots & \ddots &  \\ 
%		&         &         &         & C_{n\!+\!\ell} & B_{n\!+\!\ell} & A_{n\!+\!\ell}
%}}_{=:\cM}
%\! 
%\underbrace{\m{x(n) \\ x(n\!+\!1)  \\ x(n\!+\!2) \\ \vdots \\ x(n\!+\!\ell)}}_{=:\cX} 
%+
%\]
%%
%\be\label{inflated}
%+ \underbrace{\m{
%		D_n &         &         & \\
%		& D_{n+1} &  		& \\
%		&         & \ddots  & \\
%		&         &         & D_{n+\ell}
%}}_{=:\cN}
%\underbrace{\m{u(n) \\ u(n\!+\!1)  \\ \vdots \\ u(n\!+\!\ell)}}_{=:\cU} 
%= \! \underbrace{\m{f(n) \\ f(n\!+\!1)  \\ \vdots \\ f(n\!+\!\ell)}}_{=:\cG}, \ \mbox{ for all } n\geq n_0.
%\ee
%
\begin{align}\label{inflated}
\notag 
&\underbrace{\m{
		C_n	& B_n     & A_n     &         &         &  &  &  \\ 
		& C_{n\!+\!1} & B_{n\!+\!1} & A_{n\!+\!1} &         &  &  &  \\ 
		&         & \ddots  & \ddots  & \ddots  &  &  &  \\ 
		&         &         & \ddots  & \ddots  & \ddots &  &  \\ 
%		&         &         &         & \ddots  & \ddots & \ddots &  \\ 
		&         &         &         & C_{n\!+\!\ell} & B_{n\!+\!\ell} & A_{n\!+\!\ell}
	}}_{=:\cM}
	\! 
	\underbrace{\m{x(n) \\ x(n\!+\!1)  \\ x(n\!+\!2) \\ \vdots \\ x(n\!+\!\ell)}}_{=:\cX} 
	 \\ 
& + \underbrace{\m{
		D_n &         &         & \\
			& D_{n+1} &  		& \\
			&         & \ddots  & \\
			&         &         & D_{n+\ell}
			}}_{=:\cN}
\underbrace{\m{u(n) \\ u(n\!+\!1)  \\ \vdots \\ u(n\!+\!\ell)}}_{=:\cU} 
	= \! \underbrace{\m{f(n) \\ f(n\!+\!1)  \\ \vdots \\ f(n\!+\!\ell)}}_{=:\cG}, \ \mbox{ for all } n\geq n_0.
\end{align}
%
\begin{definition}\label{shift index}
Suppose that the descriptor system \eqref{eq1.0} satisfies Assumption \ref{Ass3}. The minimum number $\ell$ such that by using elementary matrix's row operations, a strangeness-free descriptor system of the form \eqref{sfree-descriptor} can be extracted from \eqref{inflated} is called the \emph{shift-index} of \eqref{eq1.0}, and be denoted by $\nu$.
\end{definition}
%In order to determine the solution $x(n)$, it would be convenience to use the underlying difference equation \eqref{underlying} than \eqref{sfree-SiDE}. Thus, we introduce the shift-index concept as follows. 
%
%\begin{definition}\label{shift index}
%At each time point $n$, the minimum number $\ell$ such that by using elementary matrix's row operations, an underlying SiDE \eqref{underlying} can be extracted from \eqref{inflated} is called the \emph{shift-index} of \eqref{eq2.2}, and be denoted by $\nu(n)$.
%\end{definition}

We give the relation between this shift-index $\nu$ and the strangeness-index $\mu$ in the following proposition.

\begin{proposition}\label{pro3.1}
Suppose that the descriptor system \eqref{eq1.0} satisfies Assumption \ref{Ass3}. If the strangeness-index $\mu$ is well-defined, then so is the shift-index $\nu$. Furthermore, we have that $\nu \leq \mu$. 
\end{proposition}
%%	
\begin{proof} 	The first claim is straight forward, since every reformulation step performed in Theorem \ref{thm2} is still a consequence of an inflated system \eqref{inflated} with $\ell = \mu$. Clearly, by definition, $\nu \leq \mu$.
\end{proof}

\begin{remark}
i) It should be noted that the difference array approach presented in this section can be extended in such a way that Assumption \ref{Ass3} can be avoided.
If this is the case, then the index $\nu$ will be a function of the time $n$. Furthermore, the strangeness-free form will be defined pointwise, and clearly, 
the characteristic values $r^{\mu}_{2}$, $r^{\mu}_{1}$,  $r^{\mu}_{0}$ will also vary in time. \\
ii) In all examples we have experienced, the equality $\mu=\nu$ holds. Nevertheless, even in the continuous time case, we have not found any references on this mater. 
This topic is currently under our investigation.
\end{remark}

Next we construct an algorithm in order to select the strangeness-free descriptor system \eqref{sfree-descriptor} from the inflated system \eqref{inflated}. 
For notational convenience, we will follow the Matlab language, \cite{matlab}. Consider the following spaces and matrices
%
\be\label{eq3.3}
\begin{array}{ll}
	\cW &:= \m{ \cM(:,3n+1 : end) & \ \cN(:,n+1 : end) }, \\
	U_1 & \mbox{basis of } \kernel(\cW^T), \ \mbox{and} \ U_{1,\perp} \mbox{basis of } \range(\cW),	
\end{array}
\ee
%
we have that $U_1^T \cW = 0$ and $U_{1,\perp}^T \cW$ has full row rank. Furthermore, the matrix $\m{U^T_1 \\ U^T_{1,\perp}}$ is nonsingular, and hence system \eqref{inflated} is equivalent to the scaled-system below. 
%
\begin{equation}\label{eq3.4a}
U_1^T \cM(:,1 : 3n) \m{x(n) \\ x(n+1) \\ x(n+2)} + U_1^T \cN(:,1:n) u(n) = U_1^T \cG,
\end{equation}
%
\begin{equation}\label{eq3.4b}
U^T_{1,\perp}  \cW \m{x(n\!+\!3) \\ \vdots \\ x(n\!+\!\nu) \\ \hline  u(n\!+\!1) \\ \vdots \\ u(n\!+\!\nu)} 
\!+\! U^T_{1,\perp} \m{ \cM(:,1\!:\!3n) & \ \cN(:,1\!:\!n)} \! \m{x(n) \\ x(n\!+\!1) \\ x(n\!+\!2) \\ \hline u(n)} \!=\! U_{1,\perp}^T \! \cG.
\end{equation}
%
Notice that due to the full row rank property of $U_{1,\perp}^T \cW$, \eqref{eq3.4b} plays no role in the determination of the strangeness-free descriptor system \eqref{sfree-descriptor}. Thus, \eqref{sfree-descriptor} is a consequence of \eqref{eq3.4a}. 
%
In the following proposition we show that system \eqref{eq3.4a} is not affected by left equivalence transformation.
%
\begin{proposition}
	Consider two left equivalent systems. Then, at the same level $\ell$, their difference-inflated systems of the form \eqref{inflated} are also left equivalent. Consequently, system \eqref{eq3.4a} is not affected by left equivalence transformation.
\end{proposition}
%
\begin{proof} Let us assume that  \eqref{eq1.0} is left equivalent to the SiDE 
%
\begin{equation}\label{eq3.6}
\tA_{n} x(n+2) + \tB_{n} x(n+1) + \tC_{n} x(n)  + \tD_{n} u(n) = \tf(n),  \mbox{ for all } n\geq n_0.
\end{equation}
%
Thus, there exists a pointwise nonsingular matrix sequence $\{P_n\}_{n\geq n_0}$ such that 
%
\[ \m{\tA_{n} & \tB_{n} & \tC_{n} & \tD_{n}} = P_n \m{A_{n} & B_{n} & C_{n} & D_{n} } \mbox{ and } \tf(n) = P_n f(n) \mbox{ for all } n\geq n_0. \]
%
Therefore, the difference-inflated system of level $\ell$ to \eqref{eq3.6} takes the form
%
\begin{equation}\label{eq3.7}
\tcM \cX + \tilde{\cN} \cU = \tilde{\cG}, 
\end{equation}
%
where the matrix coefficients are
%
\[
\tcM \!=\! \diag(P_n,...,P_{n+\ell}) \ \cM, \ \tilde{\cN} \!=\! \diag(P_n,...,P_{n+\ell}) \ \cN, \ \tilde{\cG} \!=\! \diag(P_n,...,P_{n+\ell}) \cG.
\]
%
This follows that two systems \eqref{inflated} and \eqref{eq3.7} are left equivalent, which finishes the proof.
\end{proof}

For notational convenience, let us rewrite system \eqref{eq3.4a} as	
%
\be\label{eq3.13}
\m{\chA & \ \chB & \ \chC & \vline \ \chD} \m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) \\  u(n)} =  \chG. 
\ee
%	

\begin{lemma}\label{lem4.2} Consider the matrices $T_{i,\perp}$, $T_i$, $i=1$,...,$4$, $W_{1,\perp}$, $W_1$, $\chU$ as in Lemma \ref{lem1.5}. Then, system \eqref{eq3.13} has the same solution set as the following system
%
\begin{align}\label{eq3.14}
\m{
	T_{1,\perp}^T \chA 	 & \ T_{1,\perp}^T \chB  		& \ T_{1,\perp}^T \chC  		& \vline & T_{1,\perp}^T \chD \\
	%	0 					 & \ T_{1}^T \chB 	 	 		& \ T_{1}^T \chC 		 		& \vline & T_{1}^T \chD 		\\
	%	0 					 & \  \Jbone 	 	& \  \Jcone 	 	& \vline & 0 \\
	0 					 & \ T_{2,\perp}^T  \Jbone 	 	& \ T_{2,\perp}^T  \Jcone 	 	& \vline & 0 \\
	0 					 & 0 	 						& \  T_{4,\perp}^T T_{2}^T  \Jcone 	 	& \vline & 0 \\ 
	0 					 & 0 	 						& 0												 	 	& \vline & 0 \\ \hline \\[-0.35cm]
	%	0 					 & \  \Jbtwo  & \  \Jctwo 	& \vline &  \Jd \\
	0 					 & \ T_{3,\perp}^T  \Jbtwo  & \ T_{3,\perp}^T  \Jctwo 	& \vline & T_{3,\perp}^T  \Jd \\
	0 					 & 0  							& \ T_{3}^T  \Jctwo 	& \vline & T_{3}^T  \Jd} 
\! \m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) \\  u(n)} =  \chU \chG.
% U:= \m{ T_{1,\perp}^T					 \\
%T_{2,\perp}^T W_{1}^T T_{1}^T		 \\
%T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T   \\
%T_{4}^T T_{2}^T W_{1}^T  T_{1}^T         \\
%T_{4}^T T_{2}^T W_{1}^T  T_{1}^T         \\
%T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \\
%T_{3}^T W_{1,\perp}^T  T_{1}^T}
\end{align}
%	
Here the matrices $T_{1,\perp}^T \chA$, $T_{2,\perp}^T  \Jbone$,  $T_{3,\perp}^T  \Jbtwo$, $T_{2,\perp}^T  \Jcone$, and $ \Jd$ have full row rank.
\end{lemma}
\begin{proof}
Scaling system \eqref{eq3.13} with the matrix $\chU$ obtained from Lemma \ref{lem1.5} iii), we directly obtain \eqref{eq3.14}.
\end{proof}

In the following theorem we answer the question how to derive the strangeness-free formulation \eqref{sfree-descriptor} from \eqref{eq3.14}. 

\begin{theorem}\label{thm3.1} Assume that the shift index $\nu$ to the descriptor system \eqref{eq1.0} is well-defined pointwise. Furthermore, suppose that \eqref{eq1.0} satisfies Assumption \ref{Ass3}. Then, from system \eqref{eq3.4a}, we can extract the following system
%Then, there exists a matrix $\cS$ of appropriate sizes, whose rows are pairwise orthogonal, such that by scaling system \eqref{eq3.4a} with $\cS$, we obtain
%
\begin{equation}\label{sfree form}
\pm{\hr_{2} \\ \hr_{1} \\ \hr_{0} \\ \\[-0.35cm] \hat{\vphi}_{1} \\ \hat{\vphi}_{0} \\ \hv} \ 
\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
	0		& \hB_{n,2}    & \hC_{n,2}     \\
	0		&    0          & \hC_{n,3}		 \\ \hline \\[-0.35cm]
	0    & \hB_{n,5}    & \hC_{n,5}     \\
	0    & 0          & \hC_{n,6}    } \!
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} \!+\! 
\m{\hD_{n,1} \\ 0 \\ 0  \\ \hline \\[-0.35cm] \hD_{n,4} \\ \hD_{n,5}} \! u(n) \!=\! \m{\hG_1 \\ \hG_2 \\ \hG_3 \\ \hline \\[-0.35cm] \hG_4 \\ \hG_5}, \mbox{ for all } n\geq n_0,
\end{equation}
%
where the matrices $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$, $\m{\hD_{n,4} \\ \hD_{n,5}}$ 
have full row rank for all $n\geq n_0$.
Consequently, the descriptor system \eqref{eq1.0} has exactly the same solution set as the strangeness-free descriptor system \eqref{sfree form}.
\end{theorem}
\begin{proof} First we observe, that the third, fifth and sixth equations of \eqref{eq3.14} are the last three block row equations of \eqref{sfree form}. 
The remaining task is to extract the first two block row equations of system \eqref{sfree form} from \eqref{eq3.14}, by suitably removing the existence hidden redundancy.
Applying Lemma \ref{lem1.4} consecutively for two following matrix pairs
%
\[
\left(T_{2,\perp}^T  \Jbone, \ T_{4,\perp}^T T_{2}^T  \Jcone \right), \ \left(T_{1,\perp}^T \chA, \m{T_{2,\perp}^T  \Jbone \\ T_{4,\perp}^T T_{2}^T  \Jcone } \right),
\]
%
we obtain two unitary matrices $\m{S^{(i)}_{n} \\ Z^{(i)}_{n}} \in \r^{r_i,r_i}$, $i=1,2$ such that both pairs 
%
\[
\left(S^{(1)}_{n} T_{2,\perp}^T  \Jbone, \ T_{4,\perp}^T T_{2}^T  \Jcone \right), 
\left(S^{(2)}_{n}T_{1,\perp}^T \chA, \m{S^{(1)}_{n} T_{2,\perp}^T  \Jbone \\ T_{4,\perp}^T T_{2}^T  \Jcone } \right).
\]
% 
have no hidden redundancy. Scale the first and second block row equations of \eqref{eq3.14} with $S^{(2)}_{n}$ and $S^{(1)}_{n}$ respectively, we obtain the first two block row equations of \eqref{sfree form}. 
\end{proof}
%\newpage
We summarize our result in the following algorithm.
%
\begin{algorithm}[H]
	\caption{Strangeness-free formulation for SiDEs using difference arrays}
	\label{Alg2}
	\begin{algorithmic}[1]
		\State \textbf{Input:} The SiDE  \eqref{eq1.0}.
		\State \textbf{Return:} The strangeness-free descriptor system \eqref{sfree form}.
		\State Set $\ell := 0$.
		\State Construct the difference-inflated system of level $\ell$, and rewrite it in the form \eqref{inflated}.
		\State Find $U_1$ as in \eqref{eq3.3} and construct system \eqref{eq3.4a}.
		\State Find $T_i$, $T_{i,\perp}$, $i=1,...,4$, $W_1$, $W_{1,\perp}$ and construct \eqref{eq3.14} as in Lemma \ref{lem1.5}.
		\State Applying Lemma \ref{lem1.2} to reduce the hidden redundancies in two matrix pairs $\left(T_{2,\perp}^T  \Jbone, \ T_{4,\perp}^T T_{2}^T  \Jcone \right)$, $\left(T_{1,\perp}^T \chA, \m{T_{2,\perp}^T  \Jbone \\ T_{4,\perp}^T T_{2}^T  \Jcone } \right)$, and hence, to obtain system \eqref{sfree form}.
		%
%		\algstore{myalg}
%		\end{algorithmic}
%		\end{algorithm}
%		%
%		\begin{algorithm}[H]
%		\begin{algorithmic}[1]
%		\algrestore{myalg}
%		% 
		\IF{$\rank \m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}} + \rank \m{\hD_{n,4} \\ \hD_{n,5}} = d $} STOP. 
		\ELSE{ set $\ell := \ell + 1$ and go to 4} 
		\ENDIF
	\end{algorithmic}
\end{algorithm}

In order to illustrate Algorithm \ref{Alg2}, we consider a three link robot arm \cite{Hou94a} in the following example.

\begin{example}
Our consider system is of the form
%
\begin{equation*}%\label{robot arm}
\m{M_0 & 0 \\ 0 & 0} \ddot{x}(t) + \m{G_0 & 0 \\ 0 & 0} \dot{x}(t) + \m{K_0 & H_0^T \\ H_0 & 0} x(t) = \m{B_0 \\ 0} u(t).
\end{equation*}
%
Here $M_0$ represents the nonsingular mass matrix, $G_0$ the coefficient matrix associated
with damping, centrifugal, gravity, and Coriolis forces, $K_0$ the stiffness matrix, and $H_0$ the constraint. A simple discretized version of this system takes the form
%
\begin{align*}
& \m{M_0 & 0 \\ 0 & 0} \dfrac{x(n+2)-2x(n+1)+x(n)}{h^2}  + \m{G_0 & 0 \\ 0 & 0} \dfrac{x(n+2)-x(n+1)}{h} \\ & + \m{K_0 & H_0^T \\ H_0 & 0} x(n) = \m{B_0 \\ 0} u(n).
\end{align*}
%
where $h$ is the discretized stepsize.

As a simple example, let us take $M_0 = G_0 = K_0 = H_0= B_0 = 1$, $h=0.01$. Then, Algorithm \ref{Alg2} terminates after two steps and hence, the shift index is $\nu=2$ for all $n\geq n_0$. 
Furthermore, we notice that no matter forward or backward approximations has been chosen for the derivative $\dot{x}(t)$, the index remains unchanged $\nu=2$. Nevertheless, the resulting strangeness-free descriptor systems are different.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{section4_lti}
% \input{section4_ltv}

%============================================================================
\bibliographystyle{abbrv}
\bibliography{Phi_July_2019}

\appendix
\input{appendix}

\end{document}
