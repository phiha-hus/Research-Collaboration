% Editing tex file using vim in bash mode and then commit it with git

%%%%%%%%%%%class file
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
\usepackage[10pt]{extsizes}

%\smartqed % flush right qed marks, e.g. at end of proof
%%%%%%%%%%%%%%%%%
%call  packages
\usepackage[sort&compress]{natbib}
\usepackage{lipsum}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pdfoutput=1
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algcompatible}

%\usepackage[notcite]{showkeys}
%\usepackage{color}
%\usepackage{showlabels}
%\renewcommand{\showlabelfont}{\small\slshape\color{red}}

\usepackage{lineno}
\linenumbers

\usepackage{graphicx}
\usepackage{amssymb,amsmath,bm,mathrsfs}
\let\proof\relax\let\endproof\relax
% Using the package amsthm leads to confliction ''The \begin{proof} is already defined''
\usepackage{amsthm}
\usepackage{mathabx}
\usepackage{hyperref} %$#

%%%%%%%%%%%%%%%%%

%Math environments===========================================================
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{example}[theorem]{Example}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{remark}[theorem]{Remark}
%\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{hypo}[theorem]{Hypothesis}
\renewcommand{\labelenumi}{\roman{enumi}}
\numberwithin{equation}{section}
\newtheorem{procedure}[theorem]{Procedure}

\include{command}

%===============================================================================
\begin{document}
	
%\title{Regularization of Second Order Singular Difference Equations\footnotemark[1]}
%\titlerunning{Regularization of Second Order Singular Difference Equations}% Part of RIGHT running header
\title{Solvability Analysis of Second Order, Discrete Time Descriptor Systems \footnotemark[1]}
\titlerunning{Solvability Analysis of Second Order, Discrete Time Descriptor Systems} % Part of RIGHT running header
\author{ {\sc Phi Ha %\thanks{This work was supported by the research project Naforsted, and was done during the first author's visit at VIASM}
	and Vu Hoang Linh}}
	%\authorrunning{Short author list}% Part of LEFT running header

\institute{Phi Ha and Vu Hoang Linh \at Institute of Math-Mechanics-Informatics, Hanoi University of Science, VNU \\ 	Nguyen Trai Street 334, Thanh Xuan, Hanoi, Vietnam\\ 
		\email{\{haphi.hus;linhvu\}@vnu.edu.vn}
	}
\date{Version 1 : 27/02/2019 \\ Received: date / Accepted: date}      
	
\maketitle
	
\begin{abstract}
This paper is devoted to the analysis of linear, second order \emph{discrete time descriptor systems} (or singular difference equations (SiDEs) with control). 
Following the algebraic approach proposed in \cite{KunM94a,KunM94b}, first we present a theoretical framework to analyze the corresponding initial value problem for SiDEs, which is followed by the analysis of descriptor systems.
We also describe numerical methods to determine the structural properties related to the solvability analysis of these systems. 
%Finally, we discuss the regularizability and impulse-controllability of descriptor systems via different types of feedbacks. 
This work extends and completes the researches in  \cite{Bru09,MehS06,LosM08}.
\end{abstract}
	
\noindent
{\bf Keywords:} Singular systems; Difference equation; Descriptor systems; \linebreak Strangeness-index; Regularization; Feedback.

\noindent
{\bf AMS Subject Classification:} 34A09, 34A12, 65L05, 65H10
%===============================================================================

\section{Introduction and Preliminaries}\label{intro}

In this paper we study second order, discrete time descriptor systems of the form
%
\begin{equation}\label{eq1.0}
A_n x(n+2) + B_{n} x(n+1) + C_{n} x(n) + D_{n} u(n)  = f(n),\ \mbox{ for all } n \geq n_0. 
\end{equation}
%
We will also discuss the initial value problem of the associated singular difference equation (SiDE) 
%
\begin{equation}\label{eq1.1}
A_n x(n+2) + B_{n} x(n+1) + C_{n} x(n) = f(n),\ \mbox{ for all } n \geq n_0,
\end{equation}
%
together with some given initial conditions
%
\begin{equation}\label{eq1.2}
x(n_0+1)=x_{1}, \ x(n_0)=x_{0}.
\end{equation}
%
Here the solution/state $x=\{ x(n) \}_{n\geq n_0}$, the inhomogeneity $f=\{ f(n) \}_{n\geq n_0}$, the input function $u=\{ u(n) \}_{n\geq n_0}$, where $x(n) \in \C^d$, $f(n) \in \C^m$ and $u(n) \in \C^p$ for each $n \geq n_0$. The coefficients contain three matrix sequences $\{A_{n}\}_{n\geq n_0}$, $\{B_{n}\}_{n\geq n_0}$, $\{C_{n}\}_{n\geq n_0}$ which always take values in $\C^{m,d}$, and $\{D_{n}\}_{n\geq n_0}$ which take values in $\C^{m,p}$. 

The SiDE \eqref{eq1.1}, on one side, can be consider as the resulting equations, obtained by finite difference or discretization of some continuous-time DAEs or constrained PDEs. One the other side, there are also many models/applications in real-life, which lead to SiDEs, for example Leotief economic models, backward Leslie model in biology, etc. 

While both first order DAEs and SiDEs have been well-studied from both theoretical and numerical sides,
the same maturity has not been reached for higher order systems. 
In classical literatures \cite{Aga00,Ela13,Kel01}, usually new variables are introduced to present some chosen derivatives of the state variable $x$ such that a high order system can be reformulated as a first order one. This method, however, is not only non-unique but also has presented some substantial disadvantages. As have been fully discussed in \cite{LosM08,MehS06} for continuous time systems, these disadvantages include: (1st) increase the index of the system, and therefore the complexity of the numerical method to solve it; (2nd) increase the computational effort, because of the bigger size of a new system; (3rd) affect the controllability/observability of the corresponding descriptor system, since there exist situations where a new system is uncontrollable while the original one is. 
%%This fact is well-known for continuous time systems (e.g. \cite{LosM08}), where one can control just the state in a multi-body system but not always its velocity. 
%Moreover, introducing new variables may also require associated initial conditions, which is not always available. For example one cannot require an initial condition of an input function. 
Therefore, the \emph{algebraic approach}, which treats the system directly without reformulating it, has been presented in \cite{LosM08,MehS06,Wun06,Wun08} in order to overcome the disadvantages mentioned above.

%these disadvantages include: (1st) increase the index of the system, and therefore the complexity of the numerical method to solve it; (2nd) increase the computational effort, because of the bigger size of a new system; (3rd) affect the controllability/observability of the given system, since there exist situations where a new system is uncontrollable while the original one is. 
%%This fact is well-known for continuous time systems (e.g. \cite{LosM08}), where one can control just the state in a multi-body system but not always its velocity. 
%Moreover, introducing new variables may also require associated initial conditions, which is not always available. For example one cannot require an initial condition of an input function. 
%
%The algebraic approach, which treats the system directly without reformulating it, 
%has demonstrated its applicability to overcome the disadvantages above, as has been contemplated in \cite{LosM08,MehS06,Wun06,Wun08}. 
%
Nevertheless, even for second order SiDEs, this method has not yet been considered. Therefore, the main aim of this article is to set up a comparable framework for second order SiDEs/descriptor systems. It is worth marking that the algebraic method proposed in \cite{MehS06,LosM08} is applicable theoretically but not numerically, due to two reasons: (1) The condensed form of the matrix coefficients are very big and complicated. (2) The system's transformations are not unitary. In this work, we will modify this method to make it more concise and also be computable in a stable way.    

The outline of this paper is as follows. After recalling some preliminary concepts and some auxiliary lemmata, in Sections \ref{Sec2} and \ref{Sec2b} we consecutively introduce \emph{index reduction procedures} for SiDEs and for descriptor systems, based on condensed forms that allow us to determine structural properties such as existence and uniqueness of a solution, consistency and hidden constraints, etc.
For the numerical solution of these systems, we consider in Section \ref{Sec3} the \emph{shift array approach} to bring the original system to its strangeness-free form. The presented algorithms are demonstrated by numerical experiments. 
%In \ref{Sec4} we discuss the regularization and impulse-controllability of descriptor systems via different types of feedback control. In particular, we establish verifiable conditions for the impulse controllability in terms of the system's coefficients.  
Finally, we finish with some conclusion.\\

In the following example we demonstrate some difficulties that may arise in the analysis of second order SiDEs.
%
\begin{example}\label{Exa2}
Consider the following second order SiDE, motivated from Example 2, \cite{MehS06}.
%
\[
\m{1 & 0 \\ 0 & 0} x(n+2) + \m{1 & 0 \\ 0 & 0} x(n+1) + \m{0 & 1 \\ 1 & 0} x(n) = \m{f_1(n) \\ f_2(n)}, \ n\geq n_0.  
\]
%
Clearly, from the second equation $\m{1 & 0} x(n) = f_2(n)$, we can shift the time $n$ to obtain 
%
\[
 \m{1 & 0} x(n+1) = f_2(n+1)  \ \mbox{ and } \ \m{1 & 0} x(n+2) = f_2(n+2).
\]
%
Inserting these to the first equation of the original system, we find out the hidden constraint $f_2(n+2) + f_2(n+1) + \m{0 & 1} x(n) = f_1(n)$. 
Consequently, we obtain the following system, which possess a unique solution
%
\[
 \m{0 & 1 \\ 1 & 0} x(n) = \m{f_1(n) -f_2(n+2) - f_2(n+1)  \\ f_2(n)}, \ n\geq n_0.
\]
%
Let $n=n_0$ in this new system, we obtain a constraint that $x(n_0)$ must obey.
This example showed us some important facts. Firstly, one can use some shift operators and row-manipulation (Gaussian eliminations) to derive hidden constraints. Secondly, the solution only exists if the initial condition fulfills some consistency conditions.
\end{example}

For matrices $Q\in \C^{q,n}$, $P\in\C^{p,n}$, the pair $(Q,P)$ is said to
\emph{have no hidden redundancy} if
%
\[
\rm{rank} \left(\m{Q \\ P} \right) = \rm{rank} (Q) + \rm{rank}(P).
\]
%
Otherwise, $(Q,P)$ is said to \emph{have hidden redundancy}.
%
Notice that, if $\m{Q \\ P}$ is of full row rank then obviously, the pair $(Q,P)$ has no hidden redundancy. However, the converse is not true as is obvious for $Q=\m{1 & 0 \\ 0 & 0}$, $P=\m{0 & 1 \\ 0 & 0}$.

\begin{lemma}\label{lem1.1}(\cite{HaM12}) Suppose that for  $Q \in \C^{q,n}$, $P\in\C^{p,n}$, the pair
$(Q,P)$ has no hidden redundancy. Then, for any matrix $U\in C^{q,q}$ and any $V \in C^{p,p}$, the pair
$(UQ,VP)$ has no hidden redundancy.
\end{lemma}

\begin{lemma}\label{lem1.3}(\cite{HaM12})
	Consider $k+1$ full row rank matrices $R_0 \in \C^{r_0,n},\dots, R_k \in \C^{r_k,n}$, and assume that for $j=k,\dots,1$ none of the matrix pairs $\left(R_j, \m{R_{j-1} \\ \vdots \\ R_0} \right)$ has a hidden redundancy.
	Then, $\m{R_k \\ \vdots \\ R_0}$ has full row rank.
\end{lemma}

Lemma \ref{lem1.2} below will be very useful later for our analysis, in order to remove hidden redundancy in the system's coefficients.

\begin{lemma}\label{lem1.2}
For $Q\in \C^{q,n}$, $P\in\C^{p,n}$, there exists $\m{S & 0 \\ Z_1 & Z_2} \in \C^{q,q+p}$ such that the following conditions hold.
\begin{enumerate}
	\item[i)] $\m{S \\ Z_1} \in C(\bbI,\C^{p,p})$ is pointwise unitary, and $Z_1 P + Z_2 Q = 0$,
	\item[ii)] the function $SP$ has pointwise full row rank, and the pair $(SP,Q)$ has no hidden redundancy.
\end{enumerate}
	%
\end{lemma}
%
\begin{proof} First using SVD we factorize $Q$ and then partition $P$ conformably to get
%
\begin{equation}\label{eq2.4}
U_1^H  Q V_1 = \m{\Si & 0 \\ 0 & 0 }, \ \mbox{and} \ PV_1 = \m{P_1 & P_2},
\end{equation}
%
where $U_1=\m{U_{11} & U_{12}} \in \C^{q,q}, \ V_1=\m{V_{11} & V_{12}} \in \C^{n,n}$ are unitary and $\Si \in \C^{r_Q,r_Q}$ is diagonal. 
Now we use a second SVD to factorize $P_2$ and to find a unitary matrix $U^H_2= \m{S \\ Z_1} \in \C^{p,p}$ such that $U_2^H P_2 = \m{P_{12} \\ 0}$, where $P_{12}$ has full row rank. 
Thus, we obtain
%
\[
\m{S & 0 \\ Z_1 & 0 \\ 0 & U_{11}^H \\ 0 & U_{12}^H} \m{P \\ \hline  Q} \m{V_{11} & V_{12}} =
\m{
	P_{11} & P_{12} \\
	P_{21} & 0 \\ \hline
	\Si & 0 \\
	0   & 0
}.
\]
%
Since $P_{12}$ has full row rank, $SP=\m{P_{11} & P_{12}}V_1^{-1}$ also has full row rank. Moreover, one sees that
%
\[ \rank \left( \m{SP \\ Q} \right) = \rank \left(\m{0 & P_{12}} \right) + \rank \left(\m{\Si & 0} \right) = \rank(SP) + \rank(Q),
\]
%
which follows that the pair $(SP,Q)$ has no hidden redundancy.\\
Finally, setting $Z_2 := - P_{21}\Si^{-1}U_{11}^H$, we obtain
%
\[ Z_1 P + Z_2Q = \left( [P_{21} \quad 0] - P_{21} \Si^{-1} [\Si \quad 0] \right) V_1^{-1} = 0, \]
%
which completes the proof.
\end{proof}
%
\begin{remark}\label{rem1}
	It should be noted, that the matrices $U_1$, $U_2$, $V_1$ in the proof of Lemma \ref{lem1.6} are orthogonal. Therefore, in case that the singular values of $Q$ are neither too small nor too big, then $\Si^{-1}$ is well-conditioned, and hence we can stably compute the matrix $Z_2$. Both matrices $Z_1$ and $Z_2$ will play the key role in our \emph{index reduction procedure} presented in the next section.
\end{remark}

For any given matrix $M$, by $M^T$ we denote its transpose. By $T_0(M)$ we denote an orthogonal matrix whose columns span the left null space of $M$. By $T_{\perp}(M)$ we denote an orthogonal matrix whose columns span the vector space $\range(M)$. 
%We notice that, even though these matrices are not uniquely determined, the left/right null spaces of $M$ are. Thus, for simplicity, we speak of these matrices as the corresponding spaces.
From basic linear algebra, we have the following three lemmata.

\begin{lemma}\label{lem1.4} The following identity holds
\[
\m{T^T_{\perp}(M) \\ T^T_0(M)} M = \m{T^T_{\perp}(M) \ M \\ 0 }, 
\]
and $T^T_{\perp}(M) \ M$ has full row rank. 
\end{lemma}
\begin{proof}
A simple proof can be found in, for example, \cite{GolV96}.
\end{proof}

\begin{lemma}\label{lem1.5} Given four matrices $\chA$, $\chB$, $\chC$ in $\C^{m,d}$ and $\chD$ in $\C^{m,p}$. Let us consider the following matrices whose columns span orthonormal bases of the associated vector spaces
	\[
	\begin{array}{lllll}
	T_{1} & \mbox{basis of } \kernel(\chA^T), & \mbox{ and } & T_{1,\perp} & \mbox{basis of } \range(\chA),\\
	W_{1} & \mbox{basis of } \kernel(T_1^T \chD)^T, & \mbox{ and } & W_{1,\perp} & \mbox{basis of } \range(T_1^T \chD),\\
	T_{2} & \mbox{basis of } \kernel(W_1^T T_1^T \chB)^T, & \mbox{ and } & T_{2,\perp} & \mbox{basis of } \range(W_1^T T_1^T \chB),\\
	T_{3} & \mbox{basis of } \kernel(W_{1,\perp}^T T_1^T \chB)^T, & \mbox{ and } & T_{3,\perp} & \mbox{basis of } \range(W_{1,\perp}^T T_1^T \chB), \\
	T_{4} & \mbox{basis of } \kernel(T_{2}^T W_{1}^T T_{1}^T  \chC)^T, & \mbox{ and } & T_{4,\perp} & \mbox{basis of } \range(T_{2}^T W_{1}^T T_{1}^T  \chC).
	\end{array}
	\]
	Then, the following assertions hold true.
	\begin{enumerate}
		\item[i)] The matrices $\m{T_{i,\perp} \\ T_{i} }$, $i=1,...,4$, $\m{W_{1,\perp} \\ W_1}$ are orthogonal.
		\item[ii)]	The matrices $T_{1,\perp}^T \chA$, $T_{2,\perp}^T W_{1}^T T_{1}^T  \chB$,  $T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chB$, $T^T_{4,\perp} T_{2}^T W_{1}^T T_{1}^T  \chC$, \linebreak and $\m{ T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chD \\ T_{3}^T W_{1,\perp}^T  T_{1}^T  \chD}= \m{ T_{3,\perp}^T \\ T_{3}^T}  W_{1,\perp}^T  T_{1}^T  \chD$ have full row rank.
		\item[iii)] Moreover, there exists a nonsingular matrix $\chU$ such that 
		%
		\be\label{eq1.10}
		\chU \m{\chA & \chB & \chC & \vline & \chD}
		\!=\! \m{
			T_{1,\perp}^T \chA 	 & \ T_{1,\perp}^T \chB  		& \ T_{1,\perp}^T \chC  		& \vline & T_{1,\perp}^T \chD \\
			%	0 					 & \ T_{1}^T \chB 	 	 		& \ T_{1}^T \chC 		 		& \vline & T_{1}^T \chD 		\\
			%	0 					 & \ W_{1}^T  T_{1} \chB 	 	& \ W_{1}^T  T_{1}^T  \chC 	 	& \vline & 0 \\
			0 					 & \ T_{2,\perp}^T W_{1}^T T_{1}^T  \chB 	 	& \ T_{2,\perp}^T W_{1}^T T_{1}^T  \chC 	 	& \vline & 0 \\
			0 					 & 0 	 						& \  T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC 	 	& \vline & 0 \\ 
			0 					 & 0 	 						& 0												 	 	& \vline & 0 \\ \hline \\[-0.35cm]
			%	0 					 & \ W_{1,\perp}^T  T_{1}^T  \chB  & \ W_{1,\perp}^T  T_{1}^T  \chC 	& \vline & W_{1,\perp}^T  T_{1}^T  \chD \\
			0 					 & \ T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chB  & \ T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chC 	& \vline & T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chD \\
			0 					 & 0  							& \ T_{3}^T W_{1,\perp}^T  T_{1}^T  \chC 	& \vline & T_{3}^T W_{1,\perp}^T  T_{1}^T  \chD} \ .
		\ee
	\end{enumerate}	
		%		
\end{lemma}
\begin{proof} The first two claims followed directly from Lemma \ref{lem1.4}, while the desired matrix $\chU$
in the third part is
	%
	\[
    \chU :=
 \m{  I &\vline  &  	&		 & \vline & 	\\ \hline \\[-0.35cm]
		&\vline  & I  & 			 & \vline & 	\\
		&\vline  &    & T_{4,\perp}^T & \vline &     \\ 
		&\vline  & 	& T_{4}^T 		 & \vline &     \\ \hline \\[-0.35cm]
		&\vline  & 	&			 & \vline &  I}  
	\cdot
	\m{I &\vline &  			 & \vline & 	\\ \hline \\[-0.35cm]
		&\vline & T_{2,\perp}^T & \vline &     \\ 
		&\vline & T_{2}^T 		 & \vline &     \\ \hline \\[-0.35cm]
		&\vline & 				 & \vline &  T_{3,\perp}^T   \\ 
		&\vline & 		 		 & \vline &  T_{3}^T } 
	\cdot 
	\m{I &  \vline & \\ \hline \\[-0.35cm] & \vline & W_{1}^T \\ & \vline & W_{1,\perp}^T} 
	\cdot
	\m{T_{1,\perp}^T \\ T_1^T} \ .
	\]
	%
\end{proof}

\begin{lemma}\label{lem1.6} Let $P\in\C^{p,n}$, $Q \in \C^{q,n}$ be two full row rank matrices and $p+q\leq n$. Then, the following assertions hold true.
\begin{enumerate}
\item[i)] There exists a matrix $F\in \C^{n,n}$ such that $H := \m{P \\ QF}$ has full row rank.
\item[ii)] For any $G\in \C^{q,n}$, there exists a matrix $F\in \C^{n,n}$ such that $\m{P \\ G+QF}$ has full row rank.
\end{enumerate}	
\end{lemma}
\begin{proof}
i) First we consider the SVDs of $P$ and $G$ that reads
%
\begin{equation*}
U_P P V_P = \m{\Si_P & \ 0_{p,n-p}}, \quad U_Q Q V_Q = \m{\Si_Q & \ 0_{q,n-q}},
\end{equation*}
%
where $\Si_P$, $\Si_Q$ are nonsingular, diagonal matrices, and $0_{p,n-p}$ (resp. $0_{q,n-q}$) are the zero matrix of size $p$ by $n-p$ (resp. $q$ by $n-q$).\\
By choosing $F:= V_Q \ \m{0 & I_q \\ I_{n-q} & 0} \ V_P^{-1}$ we see that
%
\[ 
\m{U_P & 0 \\ 0 & U_Q} \ \m{P \\ QF} \ V = \m{U_P P V_P \\ U_Q QF V} = \m{\Si_P & 0_{p,n-p-q} & 0_{p,q} \\ 0_{q,p} & 0_{p,n-p-q} & \Si_Q}, \]
%
and hence, the claim i) is proven.\\
ii) Clearly, in case that the matrix $F$ is very big, then $G$ is only a small perturbation, and hence for sufficiently large $\varepsilon$, by choosing 
%
\[ F := \varepsilon V_Q \ \m{0 & I_q \\ I_{n-q} & 0} \ V_P^{-1} \]%
we obtain the full row rank property of $\m{P \\ G+QF}$. 
\end{proof}

\begin{remark}\label{rem1.1}
It should be noted that, the proof of Lemmata \ref{lem1.5} and \ref{lem1.6} are constructive. Furthermore, all the matrices $T_{i,\perp}$, $T_{i}$, $i=1,...,4$, $W_{1,\perp}$, $W_1$ and $F$ in these lemmata can be stably computed.
\end{remark}
%=================================================================
%\section{Strangeness-index of high-order SiDEs}\label{Sec2}
%
%In this section, we study the analysis of high-order SiDEs of the form \eqref{eq1.1} and of the IVP \eqref{eq1.1}--\eqref{eq1.2}. First we consider a second order SiDE, i.e. $k=2$. For notational convenience, we change the notation of the matrix sequence coefficients $(A^{(k)}_n)_{n\geq n_0}$ and rewrite our SiDE as follows
%%
%\begin{equation}\label{eq2.1}
%A_{n} x(n+2) + B_{n} x(n+1) + C_{n} x(n) = f(n),\ \mbox{ for all } n \geq n_0.
%\end{equation}
%%

\section{Strangeness-index of second-order SiDEs}\label{Sec2}

In this section, we study the solvability analysis of the second-order SiDE \eqref{eq1.1} and of its corresponding IVP \eqref{eq1.1}--\eqref{eq1.2}. It is well-known that the unique solvability of this IVP is closely related to the \emph{regularity} of the matrix triple $(A_n,B_n,C_n)$, as will be recalled in the following lemma.\\

\begin{lemma}\label{regular triple}(\cite{MehS06}) 
Consider the IVP \eqref{eq1.1}--\eqref{eq1.2}. Then, this IVP is uniquely solvable for any function sequence $f=\{ f(n) \}_{n\geq n_0}$ if and only if the matrix triple $(A_n,B_n,C_n)$ is \emph{regular} for all $n\geq n_0$, i.e., the polynomial $\det(\lb^2 A_n + \lb B_n + C_n)$ is not identically zeros.	
\end{lemma}

Many regularization procedures and their associated index concepts have been proposed for first order systems, see the survey \cite{Meh13} and the references therein. Nevertheless, for second order systems, only the strangeness-index has been proposed for only continuous time systems in \cite{MehS06,Wun08}. Thus, it is our purpose to establish an index concept for system \eqref{eq1.1}. Furtheremore, we will consider some modifications in order to make the \emph{algebraic approach} more concise and better for not only theoretical analysis but also for numerical computation. 

Let
%
\begin{equation*}
M_n \!:= \m{A_{n} & B_{n} & C_{n}}, \
X_n \!:=\! \m{x(n+2) \\ x(n+1) \\ x(n)},
\end{equation*}
%
we call $\{M_n\}_{n\geq n_0}$ the \emph{behavior matrix sequence} of system  \eqref{eq1.1}. Thus,   \eqref{eq1.1} can be rewritten as
%
\begin{equation}\label{eq2.2}
M_n X_n = f(n), \mbox{ for all } n\geq n_0.
\end{equation}
%
Clearly, by scaling  \eqref{eq1.1} with a nonsingular matrix $P_n\in \C^{\ell,\ell}$, we obtain a new system
%
\begin{equation}\label{eq2.3}
\m{P_nA_{n} & P_nB_{n} & P_nC_{n}} X_n = P_n f(n), \mbox{ for all } n\geq n_0,
\end{equation}
%
without changing the solution space. This motivates the following definition.
%
\begin{definition}\label{defstrleq}	Two behavior matrix sequences $\{M_n =\m{A_{n} & B_{n} & C_{n}} \}_{n\geq n_0}$ and $\{\tM_n =\m{\tA_{n} & \tB_{n} & \tC_{n}}\}_{n\geq n_0}$ are called \emph{(strongly) left equivalent} if there exists a pointwise nonsingular matrix sequence $\{P_n\}_{n\geq n_0}$ such that $\tM_n = P_n M_n$ for all $n\geq n_0$. 
We denote this equivalence by $\{M_n\}_{n\geq n_0} \lsim \{\tM_n\}_{n\geq n_0}$.	
If this is the case, we also say that two SiDEs  \eqref{eq1.1}, \eqref{eq2.3} are left equivalent.
\end{definition}

\begin{lemma}\label{lem2.1}
Consider the behavior matrix sequence $\{M_n\}_{n\geq n_0}$ of system  \eqref{eq1.1}. Then, for all $n\geq n_0$, we have that
%
\begin{equation}\label{block-upper-M}
\{M_n\}_{n\geq n_0} \  \lsim  \ \left\{ 
	\m{A_{n,1}& B_{n,1}    & C_{n,1}     \\
	0	& B_{n,2}    & C_{n,2}     \\
	0	&    0          & C_{n,3} \\  
		0     & 0            & 0} \right\}_{n\geq n_0}, \qquad
	\pm{r_{2,n} \\ r_{1,n} \\ r_{0,n} \\ v}
	\end{equation}
where the matrices $A_{n,1}$, $B_{n,2}$, $C_{n,3}$ on the main diagonal have full row rank. Furthermore, the numbers $r_{2,n}$, $r_{1,n}$, $r_{0,n}$, $v$ are invariant under global left equivalent transformations.
Thus, we can call them the \emph{local characteristic invariants of the SiDE \eqref{eq1.1}}.
\end{lemma}
%
\begin{proof} The block diagonal form \eqref{block-upper-M} is obtained directly by consecutively compressing the block columns $A_{n}$, $B_{n}$, $C_{n}$ of $M$ via Lemma \ref{lem1.4}. From \eqref{block-upper-M}, we obtain the following identities
%
\bens
r_{2,n} &=& \rank(A_{n}), \\
r_{1,n} &=& \rank(\m{A_{n} & B_{n}}) - \rank(A_{n}), \\
r_{0,n} &=& \rank(\m{A_{n} &  B_{n} & C_{n}}) - \rank(\m{A_{n} & B_{n}}),
\eens
%
which proves the second claim.	
\end{proof}

In analoguous to the continuous-time case, we will apply an \emph{algebraic approach} (see \cite{Bru09,MehS06}), which aims to reformulate   \eqref{eq1.1} into a so-called \emph{strangness-free} form, as stated in the following definition.

\begin{definition}\label{Def strangeness-free}
System  \eqref{eq1.1} is called \emph{strangeness-free} if there exists a pointwise-nonsingular matrix sequence $\{P_n\}_{n\geq n_0}$ such that by scaling the SiDE  \eqref{eq1.1} at each point $n$ with $P_n$, we obtain a new system of the form
%
\be\label{def sfree}
\pm{\hr_2 \\ \hr_1 \\ \hr_0 \\\hv } \quad 
\m{\hA_{n,1} \\ 0 \\ 0 \\ 0} x(n\!+\!2) + \m{ \hB_{n,1} \\ \hB_{n,2} \\ 0 \\ 0} x(n\!+\!1) + \m{ \hC_{n,1} \\ \hC_{n,2} \\ \hC_{n,3} \\ 0} x(n)  = \m{ \hat{f}_1(n) \\  \hat{f}_2(n) \\  \hat{f}_3(n) \\ \hat{f}_4(n)}, \ \mbox{for all} \ n\geq n_0, 
\ee
%
where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank for all $n\geq n_0$. 
\end{definition}

\begin{remark}
We notice that, if the SiDE \eqref{eq1.1} is of the strangeness-free form \eqref{def sfree}, then it is regular if and only if the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ is invertible for all $n\geq n_0$. Furthermore, in \eqref{def sfree} the last block row equation must not appear, i.e. $\hv=0$.
\end{remark}

In order to perform an algebraic approach, the additional assumption below is usually needed.

\begin{assumption}\label{Ass1}
Assume that the local characteristic invariants $r_{2,n}$, $r_{1,n}$, $r_{0,n}$ become global, i.e., they are constant for all $n\geq n_0$. 
\end{assumption}

Due to Lemma \ref{lem2.1}, we see that Assumption \ref{Ass1} is satisfied if and only if $\rank(A_{n})$, $\rank(\m{A_{n} & B_{n}})$, $\rank(\m{A_{n} &  B_{n} & C_{n}})$ do not depend on $n$. Let us call the number $r_u := 3 r_2 + 2 r_1 + r_0$ the \emph{upper rank} of $M_n$. Clearly, $r_u$ is invariant under left equivalence transformations. Rewriting \eqref{eq2.2} block row-wise, we obtain the following system for all $n\geq n_0$.
%
\begin{subequations}\label{eq2.5}
	\begin{alignat}{3}
	\label{eq2.5a} A_{n,1} x(n+2)  + B_{n,1} x(n+1)  + C_{n,1} x(n) &= f_1(n),& \quad r_2 \ \mbox{equations}, \\
	\label{eq2.5b} B_{n,2} x(n+1)  + C_{n,2} x(n) &= f_2(n), & \quad r_1 \ \mbox{equations}, \\
	\label{eq2.5c} C_{n,3} x(n) &= f_3(n), & \quad r_0 \ \mbox{equations}, \\
	\label{eq2.5d} 0 &= f_4(n),& \quad v \ \mbox{equations}.
	\end{alignat}
\end{subequations}

Since the matrices $A_{n,1}$, $B_{n,2}$, $C_{n,3}$ have full row rank, the number of scalar difference equations of order $2$ (resp. $1$, and $0$) in  \eqref{eq1.1} is exactly $r_{2}$ (resp. $r_{1}$ and $r_{0}$), while $v$ is the number of redundant equations.
%
Furthermore, we can define the shift-array operator $\De$, which acts on some or whole equations of system \eqref{eq2.5}. This operator maps each equation of system \eqref{eq2.5} 
at the time instant $n$ to the equation itself at the time $n+1$, for example
%
\[ 
 \De: C_{n,3} x(n) = f_3(n) \mapsto C_{n+1,3} x(n+1) = f_3(n+1).
 %\De: B_{n,2} x(n+1)  + C_{n,2} x(n) = f_2(n) \mapsto B_{n+1,2} x(n+2)  + C_{n+1,2} x(n+1) = f_2(n+1).
\]
%
Clearly, only under Assumption \ref{Ass1}, this shift operator can be applied to equations of system \eqref{eq2.5}. 

In order to reveal all hidden constraints of \eqref{eq2.5} we propose the idea, that for each $j=1, 2$, we use difference equations of order less than $j$ to reduce the number of scalar difference equations of order $j$. This task will be performed in Lemmata \ref{Lem2.1} and \ref{lem2.2} below.

\begin{lemma}\label{Lem2.1} Consider the behavior matrix sequence $\{M_n\}_{n\geq n_0}$ as in equation \eqref{block-upper-M}. Then, there exist matrix sequences 
$\{ S^{(i)}_{n} \}_{n\geq n_0}$, $i=1, 2$, and $\{ Z^{(j)}_{n} \}_{n\geq n_0}$, $j=1,...,5$, of appropriate sizes such that for all $n\geq n_0$, the following conditions hold true.
	\begin{enumerate}
		\item[i)] For $i=1, 2$, the matrices $\m{S^{(i)}_{n} \\ Z^{(i)}_{n}} \in \C^{r_i,r_i}$ are unitary.
		\item[ii)] The following identities hold true.
		\begin{subequations}\label{eq2.6}
			\begin{alignat}{3}
			\label{eq2.6a} Z^{(1)}_{n} B_{n,2} + Z^{(3)}_{n} C_{n+1,3} &	=	& 0, \\
			\label{eq2.6b} Z^{(2)}_{n} A_{n,1} + Z^{(4)}_{n} B_{n+1,2} + Z^{(5)}_{n} C_{n+2,3} & = & 0.
			\end{alignat}	
		\end{subequations}	
		\item[iii)] Both matrix pairs $\left(S^{(2)}_{n} A_n, \m{S^{(1)}_{n} B_{n+1,2} \\ C_{n+2,3}} \right)$, $\left(S^{(1)}_{n} B_{n,2},C_{n+1,3}\right)$ have no hidden redundancy. 
	\end{enumerate}
	%
\end{lemma}
\begin{proof}
The proof can be directly obtained by applying Lemma \ref{lem1.2} to two matrix pairs $(B_{n,2},C_{n+1,3})$ and $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$.
\end{proof}

\begin{lemma}\label{lem2.2} Consider the behavior matrix sequence $\{M_n\}_{n\geq n_0}$ in \eqref{block-upper-M}. Let the matrix sequences $\{ S^{(i)}_{n} \}_{n\geq n_0}$, $i=1, 2$ and $\{ Z^{(j)}_{n} \}_{n\geq n_0}$, $j=1,...,5$, be defined as in Lemma \ref{Lem2.1}. Then, the SiDE  \eqref{eq1.1} has exactly the same solution set as the transformed SiDE 
	%
	\[
	\pm{ d_{2} \\ s_2 \\ \hline \\[-0.35cm] d_1 \\ s_1 \\ \hline \\[-0.35cm] r_0 \\ v} \ 
	 \m{S^{(2)}_{n} A_{n,1} & S^{(2)}_{n} B_{n,1}      			   & S^{(2)}_{n} C_{n,1} 	\\
		0			& Z^{(2)}_{n} B_{n,1} + Z^{(4)}_{n} C_{n+1,2}  & Z^{(2)}_{n} C_{n,1}  \\ \hline \\[-0.35cm]
		0 			& S^{(1)}_{n} B_{n,2}  	   			   & S^{(1)}_{n} C_{n,2}  \\
		0 			& 0                			   & Z^{(1)}_{n} C_{n,2} 	\\ \hline \\[-0.35cm]
		0			& 0				 			   & C_{n,3}     \\
		0 		    & 0              			   & 0 	} 
	\m{x(n+2) \\ x(n+1) \\ x(n)} =  
	\]
	%
	\begin{equation}\label{eq2.7}
   	= \m{ S^{(2)}_{n} f_1(n) \\ Z^{(2)}_{n} f_1(n) + Z^{(4)}_{n} f_2(n+1) + Z^{(5)}_{n} f_3(n+2) \\ \hline \\[-0.35cm] S^{(1)}_{n} f_2(n) \\ Z^{(1)}_{n} f_2(n) +    	Z^{(3)}_{n} f_3(n+1) \\ \hline f_3(n) \\  f_4(n)}, \ \mbox{ for all } n\geq n_0.
	\end{equation}
	%
%	\begin{align}\label{eq2.7}
%	&\pm{ d_{2} \\ s_2 \\ \hline \\[-0.35cm] d_1 \\ s_1 \\ \hline \\[-0.35cm] r_0 \\ v} \quad 
%	&
%	\m{
%		S^{(2)}_{n} A_{n,1} & S^{(2)}_{n} B_{n,1}      			   & S^{(2)}_{n} C_{n,1} 	\\
%		0			& Z^{(2)}_{n} B_{n,1} + Z^{(4)}_{n} C_{n+1,2}  & Z^{(2)}_{n} C_{n,1}  \\ \hline \\[-0.35cm]
%		0 			& S^{(1)}_{n} B_{n,2}  	   			   & S^{(1)}_{n} C_{n,2}  \\
%		0 			& 0                			   & Z^{(1)}_{n} C_{n,2} 	\\ \hline \\[-0.35cm]
%		0			& 0				 			   & C_{n,3}     \\
%		0 		    & 0              			   & 0 
%	} 
%	\m{x(n+2) \\ x(n+1) \\ x(n)} \notag \\
%	&= 
%	&\m{ S^{(2)}_{n} f_1(n) \\ Z^{(2)}_{n} f_1(n) + Z^{(4)}_{n} f_2(n+1) + Z^{(5)}_{n} f_3(n+2) \\ \hline \\[-0.35cm] S^{(1)}_{n} f_2(n) \\ Z^{(1)}_{n} f_2(n) + Z^{(3)}_{n} f_3(n+1) \\ \hline f_3(n) \\  f_4(n)}, \ \mbox{ for all } n\geq n_0.
%	\end{align}
%	%	
Furthermore, both matrix pairs $\left(S^{(2)}_{n} A_n, \m{S^{(1)}_{n} B_{n+1,2} \\ C_{n+2,3}} \right)$, $\left(S^{(1)}_{n} B_{n,2},C_{n+1,3}\right)$ have no hidden redundancy. 
\end{lemma}
\begin{proof} 
Firstly, by scaling equation \eqref{eq2.5a} (resp. \eqref{eq2.5b}) with $\m{S^{(2)}_{n} \\ Z^{(2)}_{n}}$ (resp. $\m{S^{(1)}_{n} \\ Z^{(1)}_{n}}$), we obtain the following system without altering the solution set of \eqref{eq2.5}
%
\begin{equation}\label{eq2.8}
\m{
	S^{(2)}_{n} A_{n,1} & S^{(2)}_{n} B_{n,1}    & S^{(2)}_{n} C_{n,1} 	\\
	Z^{(2)}_{n} A_{n,1} & Z^{(2)}_{n} B_{n,1}    & Z^{(2)}_{n} C_{n,1}  \\ \hline \\[-0.35cm]
	0 			& S^{(1)}_{n} B_{n,2}  	 & S^{(1)}_{n} C_{n,2}  \\
	0 			& Z^{(1)}_{n} B_{n,2}    & Z^{(1)}_{n} C_{n,2} 	\\ \hline \\[-0.35cm]
	0			& 0				 & C_{n,3}     \\
	0 		    & 0              & 0 
} \m{x(n+2) \\ x(n+1) \\ x(n)} \!=\! 
\m{ S^{(2)}_{n} f_1 \\ Z^{(2)}_{n} f_1 \\ \hline \\[-0.35cm] S^{(1)}_{n} f_2 \\ Z^{(1)}_{n} f_2 \\ \hline \\[-0.35cm] f_3 \\ f_4 }, \quad  
\pm{ d_{2} \\ s_2 \\ \hline \\[-0.35cm] d_1 \\ s_1 \\ \hline \\[-0.35cm] r_0 \\ v} \quad .
\end{equation}
%		
Therefore, it suffices to prove, that the two systems \eqref{eq2.8} and \eqref{eq2.7} have the same solution space. \\
\textbf{Necessity:} Now let us we consider the second and third block row equations of system \eqref{eq2.5} and their shifted versions which reads
%
\ben
\label{2.5c-shift} C_{n+1,3} x(n+1) &= f_3(n+1), \\ 
\label{2.5c-doubleshift} C_{n+2,3} x(n+2) &= f_3(n+2), \\
\label{2.5b-shift} B_{n+1,2} x(n+2)  + C_{n+1,2} x(n+1) &= f_2(n+1).    
\een
%
From \eqref{eq2.6a} and \eqref{2.5c-shift}, we see that $$Z^{(1)}_{n} B_{n,2} x(n+1) = - Z^{(3)}_{n} C_{n+1,3} x(n+1) = -Z^{(3)}_{n} f_3(n+1).$$ 
Inserting this into the fourth block row equation of \eqref{eq2.8}, we obtain the first order hidden constraint
%
\begin{equation}\label{eq2.12}
Z^{(1)}_{n} C_{n,2} x(n) = Z^{(1)}_{n} f_2(n) + Z^{(3)}_{n} f_3(n+1).
\end{equation}
%
Analoguously, from \eqref{eq2.6b}, \eqref{2.5c-doubleshift}, \eqref{2.5b-shift} we see that
%
\begin{align}\label{2.10}
	Z^{(2)}_{n} A_{n,1} x(n\!+\!2)  &\!=\! -\! Z^{(4)}_{n} B_{n\!+\!1,2}x(n\!+\!2) \!-\! Z^{(5)}_{n} C_{n\!+\!2,3}x(n\!+\!2), \notag \\
									&\!=\! \!-\! Z^{(4)}_{n} \left( f_2(n\!+\!1) \!-\! C_{n\!+\!1,2} x(n\!+\!1) \right) \!-\! Z^{(5)}_{n} f_3(n\!+\!2), \notag \\
									&\!=\! Z^{(4)}_{n} C_{n\!+\!1,2} x(n\!+\!1) \!\!-\!\! Z^{(4)}_{n} f_2(n\!+\!1) \!\!-\!\! Z^{(5)}_{n} f_3(n\!+\!2).
\end{align}
%
Therefore, from the second block row equation of \eqref{eq2.8} we obtain the second order hidden constraint
%
\begin{align}\label{eq2.13}
&& \left( Z^{(2)}_{n} B_{n,1} + Z^{(4)}_{n} C_{n+1,2} \right) x(n+1) + Z^{(2)}_{n} C_{n,1} x(n) \notag \\ 
&& = Z^{(4)}_{n} f_2(n+1) + Z^{(5)}_{n} f_3(n+2) + Z^{(2)}_{n} f_1(n).
\end{align}
%
Therefore, by replacing the second and fourth block row equations of \eqref{eq2.8} with \eqref{eq2.12} and \eqref{eq2.13}, we obtain exactly system \eqref{eq2.7}.

\noindent \textbf{Sufficiency:} We will prove that if $x$ is a solution to \eqref{eq2.7}, then $x$ also fulfills \eqref{eq2.8}. 
Indeed, the fourth block equation of \eqref{eq2.8} is a direct consequence of the third and fourth block equations of \eqref{eq2.7}. 
Analogously, due to \eqref{2.10}, the second block equation of \eqref{eq2.8} is a consequence of the second, third and fourth block equations of \eqref{eq2.7}. 
These facts imply that $x$ is also the solution to \eqref{eq2.8}, and hence, this completes the proof.
\end{proof}
%
\begin{remark}
We notice that if the pair $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}} \right)$ has hidden redundancy, then $Z^{(2)}_n$ will be present in \eqref{eq2.7}. Furthermore, if $Z^{(5)}_n$ is not an empty matrix, then we need two shifts to pass from \eqref{eq2.5} to the new form \eqref{eq2.7}. 
\end{remark}
%
Comparing system \eqref{eq2.7} with \eqref{eq2.5}, we have reduced the number of second order scalar difference equations by $s_2$, increased the number of 0-order difference equations by $s_1$, while the number of 1st-order scalar difference equations is either increased or decreased by $s_2-s_1$. The upper rank of the new behavior matrix is 
%
\bens 
r_u^{new} &\leq& 3 d_2 + 2 (s_2 + d_1) + (s_1 + r_0) \\ 
          &=& 3 (r_2-s_2) + 2 (s_2 + r_1 - s_1) + (s_1 + r_0) \\ 
          &=& r-(s_2+s_1) \leq r.
\eens
%
In conclusion, after performing this \emph{index reduction step}, which passes from \eqref{eq2.5} to \eqref{eq2.7}, we have reduced the upper rank $r_u$ at least by $s_2+s_1$. 
Continuing in this way until $s_1=s_2=0$, we obtain the following algorithm.
%
\begin{algorithm}[H]
	\caption{Index reduction steps for SiDEs at the time point $n$}
	\label{Alg1}
	\begin{algorithmic}[1]
		\State \textbf{Input:} The SiDE  \eqref{eq1.1} and its behavior form \eqref{eq2.2}. Set $i=0$, $\mu=0$.
		\State \textbf{Return:} The resulting system in a special form.
		\State Transform the behavior matrix $\m{A_n & B_n & C_n}$ to the block upper triangular form
		%
		\[\tM :=
		\begin{bmatrix}
		A_{n,1} & B_{n,1}  & C_{n,1}     \\
		0       & B_{n,2}  & C_{n,2}      \\
		0       & 0        & C_{n,3}  \\ 
		0       & 0        & 0
		\end{bmatrix}, \quad
		\begin{matrix}{r_2}\\
		{r_1}\\
		{r_{0}}\\  
		{v}
		\end{matrix}
		\]
		where all the matrices $A_{n,1}$, $B_{n,2}$, $C_{n,3}$ on the main diagonal have full row rank.
		%
		%
		\algstore{myalg}
		\end{algorithmic}
		\end{algorithm}	
		\begin{algorithm}[H]
		\begin{algorithmic}[1]
		\algrestore{myalg}
		%
		\IF{both matrix pairs $\left( A_{n,1}, \m{B_{n+1,2} \\ C_{n+2,3}}\right)$ and $\left(B_{n,2},C_{n+1,3} \right)$ have no hidden redundancy} STOP. 
		%
		\ELSE{ set $i := i + 1$ and go to 6} 
		%
		\State Find the matrices $S^{(i)}_{n}$, $i=1, 2$, and $Z^{(j)}_{n}$, $j=1,...,5$ as in Lemma \ref{Lem2.1}. 				
		%
		\IF{$Z^{(5)}_n \not= [ \ ]$} set $\mu :=\mu+2$. 
		%
		%\ELSIF{$Z^{(5)}_n = [ \ ]$ and $Z^{(2)}_n \not= [ \ ]$} set $\mu :=\mu+1$. 
		%
		\ELSE{ set $\mu :=\mu+1$ and go to 6}
		%
		\ENDIF
		%
		\State Transform system \eqref{eq2.5} to system \eqref{eq2.7} as in Lemma \ref{lem2.2}.
		%
		\State Go back to 3.
		\ENDIF
	\end{algorithmic}
\end{algorithm}

After each index reduction step the upper rank $r^{i}_u$ has been decreased at least by $s^{i}_2+s^{i}_1$, so Algorithm \ref{Alg1} terminates after a finite number $\mu$ of iterations, which will be called the \emph{strangeness-index} of the SiDE  \eqref{eq1.1}.

\begin{theorem}\label{thm2.1} Consider the SiDE \eqref{eq2.2} and assume that Assumption \ref{Ass1} is satisfied for any $n$ and any considered $i$ in the loop. 
Then, the SiDE  \eqref{eq1.1} has the same solution set as the strangeness-free-SiDE
	%
	\be\label{sfree-SiDE}
	\pm{r^{\mu}_{2} \\ r^{\mu}_{1} \\ r^{\mu}_{0} \\ v^{\mu}} \qquad
	\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
		0		& \hB_{n,2}    & \hC_{n,2}     \\
		0		&    0          & \hC_{n,3} \\ 
		0       & 0          & 0}
	\m{x(n+2) \\ x(n+1) \\ x(n)} = \m{ \hg_1(n) \\  \hg_2(n) \\  \hg_3(n) \\ \hg_4(n)}, \ \mbox{for all} \ n\geq n_0, 
	\ee
	%
	where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank for all $n\geq n_0$. Here $\hg_i$, $i=1,\dots,3$, are functions of $f(n+1),\dots,f(n+\mu)$.
\end{theorem}
%
\begin{proof}
The proof is a direct consequence of Algorithm \ref{Alg1}, where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank due to Lemma \ref{lem1.3}.
%Clearly, after carrying out Algorithm \ref{Alg1}, we obtain a system of the form \eqref{sfree-SiDE}, where
%the matrices $\hA_{n,1}$, $\hB_{n,2}$, $\hC_{n,3}$ have full row rank and none of the matrix pairs 
%$\left(\hA_{n,1},\m{\hB_{n+1,2} \\ \hC_{n+2,3}}\right)$, $(\hB_{n+1,2},\hC_{n+2,3})$ has a hidden redundancy.
%Lemma \ref{lem1.3} applied to three matrices $\hA_{n,1}$, $\hB_{n+1,2}$ and $\hC_{n+2,3}$, therefore, straightly implies the second claim of this theorem.
\end{proof}

To illustrate Algorithm \ref{Alg1}, we consider the following example, motivated from Example 3, \cite{MehS06}.

\begin{example}
Consider the second order SiDE
\[
\m{ 1 & \ n\!+\!1 \\  n & \ n^2\!+\!n} x(n\!+\!2) \!+\!
\m{ 0 & \ 2 \\ 0 & 2n} x(n\!+\!1) \!+\!
\m{ 1 & \ n \\ 1\!+\!n & \ 1\!+\!n\!+\!n^2} x(n) \!=\! \m{f_{1}(n) \\ f_{2}(n) }, \ n\geq n_0.
\]
The matrix form \eqref{eq2.2} now becomes
%
\[
\underbrace{\m{
	1  & \  n+1   & \vline & 0 &  \ 2  & \vline & 1 & \ n  \\
	n  &  \ n^2+n & \vline & 0 & \ 2n & \vline & 1+n & \ 1+n+n^2  \\
	}}_{M} \m{x(n+2) \\ x(n+1) \\ x(n) } = \m{f_{1}(n) \\ f_{2}(n)}, \ n\geq n_0.
\]
%
Scale $M$ with $\m{1 & 0 \\ -n & 1}$ to bring $M$ to block diagonal form, we obtain
%
\[
\tM_0 = \m{
	1 & \ n+1 & \vline & 0  & \ 2 & \vline & 1 &  \ n  \\ \hline
	0 &  \ 0   & \vline & 0  &  \ 0 & \vline & 1 & \  1+n
} =: 
\m{A_{n,1} & B_{n,1}    & C_{n,1}     \\
	0	& 0          & C_{n,3}    
}, \quad 
\]
%
and $r_2=r_0=1$,\ $r_1=v=0$. Clearly, all constant rank conditions required in Assumption \ref{Ass1} are satisfied. 
We observe here that $B_{n,2}$ is an empty matrix for all $n\geq n_0$, and the pair $(A_{n,1},C_{n+2,3})$ has a hidden consistency. Algorithm \ref{Alg1} terminates after only one index reduction step. We have that $S_1=[ \ ]$, $Z_{11}=1$, $Z_{12}=0$, $Z_{13}=-1$, $\mu=2$ and the strangeness-free
formulation \eqref{sfree-SiDE} reads
%
\[
\m{
	0 & 0   & \vline & 0  & 2 & \vline & 1 & \ n  \\ \hline
	0 & 0   & \vline & 0  & 0 & \vline & 1 & \ 1+n
} \m{x(n+2) \\ x(n+1) \\ x(n) } = \m{f_{1}(n)-f_{2}(n+2) \\ f_2} \ .
\]
%
\end{example}

A direct consquence of Theorem \ref{thm2.1} is, that we can deduce the theoretical solvability for \eqref{eq1.1} as follows.

\begin{corollary}\label{Cor1} Consider the SiDE \eqref{eq1.1} and assume that Assumption \ref{Ass1} is satisfied for any $n$ and any considered $i$ in the loop, such that the strangeness-index $\mu$ exists. Then the followings hold.
	\begin{enumerate}
		\item[i)] The corresponding IVP for the SiDE \eqref{eq1.1} is solvable if and only if $\hg_4(n)\!=\!0$ for all $n\geq n_0$. Furthermore, it is uniquely solvable if, in addition, we have $r^{\mu}_{2} + r^{\mu}_{1} + r^{\mu}_{0} = d$.
		\item[ii)] The initial condition $x_0=x(n_0)$ is consistent if and only if the following equalities hold.
		%
		\bens 
		\hB_{n_0,2}x_1 + \hC_{n_0,2} x_0 &=& \hg_2(n_0), \\
		\hC_{n_0,3}x_0 &=& \hg_3(n_0).
		\eens 
		% 
	\end{enumerate}	
\end{corollary}

Another direct consequence of Theorem \ref{pro3.1} is, that we can obtain an underlying difference equation as follows.
%
\begin{corollary}\label{Cor2}
	Consider the SiDE \eqref{eq1.1} and assume that the corresponding IVP is uniquely solvable. Moreover, suppose that Assumption \ref{Ass1} is satisfied for any $n$ and any considered $i$ in the loop, such that the strangeness-index $\mu$ exists. 
	Then the solution to this IVP is also the solution of the \emph{underlying difference equation}
	%
	\be\label{underlying}
	\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}  x(n+2) + \m{ \hB_{n,1}  \\ \hC_{n+1,2} \\ 0} x(n+1) + \m{\hC_{n,1} \\ 0 \\ 0}	x(n) = \m{ \hg_1(n) \\  \hg_2(n+1) \\  \hg_3(n+2)},
	\ee
	%
	where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ is invertible for all $n\geq n_0$.	
\end{corollary}
%
\begin{remark} 
	i) Within one loop of Algorithm \ref{Alg1}, for each $n$, we have used 4 SVDs to remove the hidden redundancies in two matrix pairs. The total cost depends on the problems itself, i. e., depending on sizes of the matrix pairs which applied SVDs. Nevertheless, the total cost would not exceed ${\cal O}(m^2 d^2)$.\\
	ii) Different from \cite{MehS06} (see Remark 17), due to Step 7 in Algorithm \ref{Alg1}, $\mu$ is the exact number of shifts that have been used in order to achieve \eqref{sfree-SiDE}. Consequently, $x(n)$ depends on $f(n+1),\dots,f(n+\mu)$ but not $\{f(n+\mu+k)\}_{k\geq 1}$. \\ 
	iii) Unfortunately, since $Z_2$ is not orthogonal, Algorithm \ref{Alg1} could not be stably implemented. For the numerical solution to the IVP \eqref{eq1.1}-\eqref{eq1.2}, we will consider a suitable numerical scheme in Section \ref{Sec3}. \\
	iv) Unlike in \cite{LosM08,MehS06}, we do not change the variable $x$. This trick permits us to simplify significantly the condensed form in \cite{Bru09,MehS06}. This trick is also useful for the control analysis of the descriptor system \eqref{eq1.0} as will be seen later. % in Section \ref{Sec4}.	
\end{remark}

%=================================================================
\section{Strangeness-index of second order descriptor systems}\label{Sec2b}

Based on the index reduction procedure for SiDEs in Section \ref{Sec2}, in this section we construct the strangeness-index concept for the descriptor system \eqref{eq1.0}.
%%
%\begin{equation}\label{eq5.1}
%A_{n} x(n+2) + B_{n} x(n+1) + C_{n} x(n) + D_{n} u(n)= f(n),\ \mbox{ for all } n \geq n_0.
%\end{equation}
%%
%Here the matrix sequence $\{ D_{n} \}_{n\geq n_0}$ take values in $\C^{m,p}$ and $u(n) \in \C^{p}$ for all $n\geq n_0$. 
The solvability analysis for first order descriptor systems with variable coefficients have been carefully discussed in \cite{KunMR01,Rat97,ByeKM97}. Nevertheless, for second order descriptor systems, this problem has been rarely considered. We refer the interested readers to \cite{LosM08,Wun08} for continuous time systems. 

In the index reduction procedure of continuous time systems, one should avoid differentiating equations that involve an input function, due to the fact that it may not be differentiable. Here, we will also keep this spirit, and hence, will not shift any equation that involve an input function, since it may destroy the causality of the considered system. In the following lemma, we give the condensed form for system \eqref{eq1.0}.

\begin{lemma}\label{lem5.1} Consider the descriptor system \eqref{eq1.0}. Then, there exist two pointwise nonsingular matrix sequences $\{U_n\}_{n\geq n_0}$, $\{V_n\}_{n\geq n_0}$ such that the following identities hold.
	%
	\begin{align}\label{eq5.2}	
  &	(U_n \m{A_{n} & B_{n} & C_{n}}, \ U_n D_n V_n)  \notag \\ 
  &= \left( \m{A_{n,1}  & B_{n,1}    & C_{n,1}     \\
		0    & B_{n,2}    & C_{n,2}     \\
		0    & 0          & C_{n,3}     \\  \hline
		0    & B_{n,4}    & C_{n,4}     \\
		0    & 0          & C_{n,5}     \\  
		0    & 0          & 0}, \
	\m{ D_{n,11} 		& 0			& 0		  \\
		0 			& 0		    & 0		  \\
		0 			& 0		    & 0        \\	\hline 
		0      	    & \Si_{\vphi,1} 	    & 0 		 \\ 
		0     		& 0		    & \Si_{\vphi,0}       \\
		0     		& 0         & 0 } \right), \quad 
	\pm{r_{2,n} \\ r_{1,n} \\ r_{0,n} \\ \vphi_{1,n} \\ \vphi_{0,n} \\  v_n} \quad 
	\mbox{ for all } n\geq n_0.
	\end{align}	
	Here sizes of the block rows are $r_{2,n}$, $r_{1,n}$, $r_{0,n}$, $\vphi_{1,n}$, $\vphi_{0,n}$, $v_n$, the matrices $A_{n,1}$, $B_{n,2}$, $B_{n,4}$, $C_{n,3}$ are of full row rank and the matrices $\Si_{\vphi,1}$, $\Si_{\vphi,0}$ are nonsingular and diagonal.
\end{lemma}

\begin{proof}
First we apply Lemma \ref{lem1.5} to four matrices $A_n$, $B_n$, $C_n$ and $D_n$ to obtain the matrix $U_n$ that satisfies \eqref{eq1.10}. Then by decomposing the matrix $\m{T_{3,\perp}^T \\  T_{3}^T} W_{1,\perp}^T  T_{1}^T  \chD$ via one SVD, we obtain the block 
%
$ \m{
	0      	    & \Si_{\vphi,1} 	    & 0 		 \\ 
	0     		& 0		    & \Si_{\vphi,0} } \ .
$
%
Finally, by Gaussian elimination we remove all matrices on the two columns of $\chD$ that contain $\Si_{\vphi,1}$ and $\Si_{\vphi,0}$, and hence we obtain the desired form \eqref{eq5.2}.
\end{proof}

In order to build an index reduction procedure for \eqref{eq1.0}, we also need the following assumption.
%
\begin{assumption}\label{Ass2}
Assume that the local characteristic invariants $r_{2,n}$, $r_{1,n}$, $r_{0,n}$, $\vphi_{1,n}$, $\vphi_{0,n}$, $v_n$, become global, i.e., they are constant for all $n\geq n_0$. 
\end{assumption}
%

Applying Lemma \ref{lem5.1}, we can transform the descriptor system \eqref{eq1.0} to the following system
%
\begin{equation}\label{eq5.3}
\pm{r_{2} \\ r_{1} \\ r_{0} \\ \vphi_{1} \\ \vphi_{0} \\  v} \
\m{A_{n,1}  & B_{n,1}    & C_{n,1}     \\
	0    	& B_{n,2}    & C_{n,2}     \\
	0    	& 0          & C_{n,3}     \\  \hline
	0    	& B_{n,4}    & C_{n,4}     \\
	0    	& 0          & C_{n,5}     \\  
	0    	& 0          & 0} 
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) } \!+\! 
\m{ D_{n,11} 	    & 0		    & 0		  \\
	0 	    & 0		    & 0		  \\
	0 	    & 0		    & 0        \\	\hline 
	0      	    & \Si_{\vphi,1} & 0 		 \\ 
	0     	    & 0		    & \Si_{\vphi,0}       \\
	0     	    & 0             & 0 } \m{v_1(n) \\ v_2(n) \\ v_3(n)} \!=\! \tf(n),
\end{equation}
%
where $u(n) = V_n v(n)$, $v(n) := \m{v_1(n) \\ v_2(n) \\ v_3(n)}$, $\tf(n):=U_nf(n)$ for all $n\geq n_0$.\\

In this decomposition, we notice that the third and fourth block rows, whose sizes are $\vphi_1$ and $\vphi_0$, are related to the feedback regularization of \eqref{eq1.0}, as shown in the following proposition.

\begin{proposition}\label{pro5.1}
i)	Assume that for each $n\geq n_0$, the matrix $\m{A_{n,1} \\ B_{n+1,2} \\ C_{n+2,3}}$ is of full row rank.
Then, there exist two matrices $F_{n,1}$ and $F_{n,0}$ such that the following matrix has full row rank
%
\[
\m{ A_{n,1} \\ B_{n+1,2} \\ C_{n+2,3} \\ B_{n+1,4} + \m{0 & \Si_{\vphi,1} & 0} F_{n,1} \\ C_{n+2,5} + \m{0 & 0 & \Si_{\vphi,0}} F_{n,0} }.
\]
%
ii) Consequently, if the upper part of \eqref{eq5.3} is strangeness-free then there exists a first order feedback of the form
%
\be\label{eq5.5}
u(n) = F_{n,1} x(n+1) + F_{n,0} x(n), \mbox{ for all } n\geq n_0,
\ee
%	
such that the closed loop system associated with \eqref{eq3.3} is strangeness-free.	
\end{proposition}
\begin{proof}
Since the part ii) is a direct consequence of part i), we only need to prove i). The part i) is directly followed from Lemma \ref{lem1.6} with $P=\m{ A_{n,1} \\ B_{n+1,2} \\ C_{n+2,3}}$, $Q=\m{0 & \Si_{\vphi,1} & 0  \\ 0 & 0 & \Si_{\vphi,0} }$ and $G=\m{B_{n+1,4} \\ C_{n+2,5}}$.
\end{proof}

%Proposition \ref{pro5.1} motivates the following definition.
%\begin{definition}
%content
%\end{definition}
From Proposition \ref{pro5.1}, we see that we only need to remove the hidden redundancies in the upper part of 
\eqref{eq5.3}. This will be done as in the following lemma.

\begin{lemma}\label{lem5.2}
Consider the descriptor system \eqref{eq5.3}. Then, for each input sequence $\{v(n)\}_{n\geq n_0}$, it has exactly the same solution set as the following system
%
\begin{equation}\label{eq5.4}
\pm{\tr_{2} \\ \tr_{1} \\ \tr_{0} \\ \vphi_{1} \\ \vphi_{0} \\  v} \
\m{\tA_{n,1}    & \tB_{n,1}    & \tC_{n,1}     \\
	0    		& \tB_{n,2}    & \tC_{n,2}     \\
	0    		& 0            & \tC_{n,3}     \\  \hline
	0    		& B_{n,4}      & C_{n,4}     \\
	0    		& 0            & C_{n,5}     \\  
	0    		& 0            & 0} 
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) } \!+\! 
\m{ \tD_{n,11} 	& 0			& 0		  \\
	0	 		& 0		    & 0		  \\
	0 			& 0		    & 0        \\	\hline 
	0      	    & \Si_{\vphi,1} 	    & 0 		 \\ 
	0     		& 0		    & \Si_{\vphi,0}       \\
	0     		& 0         & 0 } \m{v_1(n) \\ v_2(n) \\ v_3(n)} \!=\! \tf(n),
\end{equation}
%
where $\tr_2<r_2$, $\tr_0>r_0$, $\sum_{i=0}^{2}r_i = \sum_{i=0}^{2}\tr_i$.
\end{lemma}
\begin{proof}
The system \eqref{eq5.4} is directly obtained by applying Lemma \ref{lem2.2} to the upper part of \eqref{eq5.3}. To keep the brevity of this paper, we will omit the details here.
\end{proof}

Similar to the observation made in Section \ref{Sec2}, here we also see, that the so-called \emph{index reduction step}, which passes system \eqref{eq5.3} to the new form \eqref{eq5.4} 
has reduced the upper rank $r^u$ by at least $(\tr_0-r_0)+(r_2-\tr_2)$. Continuing in this way, finally we obtain the strangeness-free descriptor system in the next theorem.

\begin{theorem}\label{thm5.1}
Consider the descriptor system \eqref{eq1.0}. Furthermore, assume that Assumption \ref{Ass2} is fulfilled whenever needed. Then, for each fixed input sequence $\{u(n)\}_{n\geq n_0}$, system \eqref{eq1.0} has the same solution set as the so-called \emph{strangness-free descriptor system} 
%
\be\label{sfree-descriptor}
\pm{\hr_{2} \\ \hr_{1} \\ \hr_{0} \\ \\[-0.35cm] \hat{\vphi}_{1} \\ \hat{\vphi}_{0} \\  \hv} \ 
\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
	0		& \hB_{n,2}    & \hC_{n,2}     \\
	0		&    0          & \hC_{n,3}		 \\ \hline \\[-0.35cm]
	0    & \hB_{n,5}    & \hC_{n,5}     \\
	0    & 0          & \hC_{n,6}     \\ 
	0    & 0          & 0} \!
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} \!+\! 
\m{\hD_{n,1} \\ 0 \\ 0  \\ \hline \\[-0.35cm] \hD_{n,4} \\ \hD_{n,5} \\ 0} \! u(n) 
\!=\! \m{\hf_1(n) \\ \hf_2(n) \\ \hf_3(n) \\ \hline \\[-0.35cm] \hf_4(n) \\ \hf_5(n) \\ \hf_6(n) }, \mbox{ for all } n\geq n_0,
\ee
%
where the matrices $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$, $\m{\hD_{n,4} \\ \hD_{n,5}}$ have full row rank for all $n\geq n_0$. 
%
\end{theorem}
\begin{proof}
By performing index reduction steps until the upper rank $r^u$ stop decreasing, we obtain the system 
%
\begin{equation*}
\pm{\hr_{2} \\ \hr_{1} \\ \hr_{0} \\ \\[-0.35cm] \hat{\vphi}_{1} \\ \hat{\vphi}_{0} \\  \hv} \quad
\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
	0		& \hB_{n,2}    & \hC_{n,2}     \\
	0		&    0          & \hC_{n,3}		 \\ \hline \\[-0.35cm]
	0       & \hB_{n,5}    & \hC_{n,5}     \\
	0    	& 0          & \hC_{n,6}     \\ 
	0    	& 0          & 0}
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} \!+\! 
\m{\hD_{n,11}		& 0			& 0		  \\
	0 			& 0		    & 0		  \\
	0 			& 0		    & 0        \\	\hline 
	0      	& \Si_{\hat{\vphi}_{1}} & 0			 \\ 
	0     		& 0		    & \Si_{\hat{\vphi}_{0}}        \\ 
	0     		& 0         & 0       	
} v(n) \!=\! \m{\hf_1(n) \\ \hf_2(n) \\ \hf_3(n) \\ \hline \\[-0.35cm] \hf_4(n) \\ \hf_5(n) \\ \hf_6(n) }, 
\end{equation*}
%
for all $n\geq n_0$, where the matrix $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$ has full row rank for all $n\geq n_0$. Here the new input sequence $\{v(n)\}_{n\geq n_0}$ satisfies $u(n)=V_nv(n)$, $V_n$ is nonsingular for all $n\geq n_0$. Transform back $v(n) = V^{-1}_n u(n)$, and set
%
\[ 
\m{\hD_{n,1} \\ 0 \\ 0 \\ \hline \\[-0.35cm] \hD_{n,4} \\ \hD_{n,5} \\ 0} :=
\m{\hD_{n,11}		& 0			& 0		  \\
	0 			& 0		    & 0		  \\
	0 			& 0		    & 0        \\	\hline 
	0      	& \Si_{\hat{\vphi}_{1}} & 0			 \\ 
	0     		& 0		    & \Si_{\hat{\vphi}_{0}}        \\ 
	0     		& 0         & 0       	
} V^{-1}, 
\]
%
we obtain exactly the strangeness-free descriptor system \eqref{sfree-descriptor}.
\end{proof}

As a direct corollary of Theorem \ref{thm5.1}, we obtain the existence and uniqueness of a solution to the closed-loop system via feedback as follows.

\begin{corollary}\label{coro5.1}
Consider the descriptor system \eqref{eq1.0}. Furthermore, assume that Assumption \ref{Ass2} is fulfilled whenever needed, so that the strangeness-free descriptor system \eqref{sfree-descriptor} is well-defined. 
Then, the following statements hold true.\\
i) There exists a first order feedback of the form \eqref{eq5.5} such that the closed-loop system is solvable if and only if $\hf_6(n)=0$ for all $n\geq n_0$. \\
ii) Furthermore, the solution to the corresponding IVP (of the closed-loop system) is unique if and only if in addition, $d=\sum_{i=0}^{2}\hr_i + \sum_{i=0}^{1}\hat{\vphi}_i$.
\end{corollary}

\begin{remark}
It should be noted that, in analogous to SiDEs, each index reduction step of the descriptor system \eqref{eq1.0} makes use of Lemma \ref{lem2.2}, where the matrices $Z^{(i)}_n$, $i=3,4,5$, may not be orthogonal. Furthermore, in Lemma \ref{lem5.1}, two matrices $U_n$, $V_n$ are only nonsingular but not orthogonal. 
Therefore, in general, the strangeness-free formulation \eqref{sfree-descriptor} could not be stably computed. For the numerical treatment of (continuous time) second order DAEs, in \cite{Wun08} a different approach was developed. We will modify it for handling SiDEs and descriptor systems in the next section.
\end{remark}
%=================================================================
\section{Shift arrays of second-order SiDEs/descriptor systems}\label{Sec3}

As have shown in two previous sections, to analyze the theoretical solvability of the SiDE  \eqref{eq1.1}
or of the descriptor system \eqref{eq1.0}, first one needs to bring it to a strangeness-free formulation. 
Nevertheless, this task is not always doable, for example when Assumptions \ref{Ass1}, \ref{Ass2} are violated at some index reduction steps. These difficulties have also been observed for continuous time systems of both first and higher orders, and they have been addressed in \cite{KunMR01,Wun08}.
The basic idea, thanks to Campbell \cite{Cam87}, while considering DAEs, is to differentiate a given system a number of times and put every one of them, including the original one, into a so-called \emph{an inflated system}. Then, the strangeness-free formulation will be determined by appropriate selection of equations inside this inflated system. In this section we will examine this approach to the descriptor system \eqref{eq1.0}. The analysis for SiDEs of the form \eqref{eq1.1} can be obtained by simply setting an input $u$ to be $0$.
%Furthermore, we assume that for each fixed input sequence $\{u(n)\}_{n\geq n_0}$ the corresponding IVP to system \eqref{eq1.0} is uniquely solvable. 
We further assume the following condition.

\begin{assumption}\label{Ass3}
Consider the descriptor system \eqref{eq1.0}. Assume that there exists a first order feedback of the form \eqref{eq5.5} such that the closed-loop system is uniquely solvable.
\end{assumption}
It should be noted that, in case of the SiDE \eqref{eq1.1}, Assumption \ref{Ass3} means that the corresponding IVP \eqref{eq1.1}-\eqref{eq1.2} is uniquely solvable.

Now let us introduce the \emph{shift-inflated system of level $\ell \in \N$} which takes the following form.
%
\bens
A_{n} x(n\!+\!2) \!+\! B_{n} x(n\!+\!1) \!+\! C_{n} x(n) \!+\! D_n u(n)&\!=\!& f(n), \notag\\
%A_{n\!+\!1} x(n\!+\!3) \!+\! B_{n\!+\!1} x(n\!+\!2) \!+\! C_{n\!+\!1} x(n\!+\!1) &\!=\!& f(n\!+\!1), \notag	\\
&\dots& \\
%A_{n\!+\!\ell\!-\!1} x(n\!+\!\ell\!+\!1) \!+\! B_{n\!+\!\ell\!-\!1} x(n\!+\!\ell) \!+\! C_{n\!+\!\ell\!-\!1} x(n\!+\!\ell\!-\!1) &\!=\!& f(n\!+\!\ell\!-\!1), \notag \\
A_{n\!+\!\ell} x(n\!+\!\ell\!+\!2) \!+\! B_{n\!+\!\ell} x(n\!+\!\ell\!+\!1) \!+\! C_{n\!+\!\ell} x(n\!+\!\ell) \!+\! D_{n\!+\!\ell} u(n\!+\!\ell) &\!=\!& f(n\!+\!\ell) \ . \notag
\eens
%
We rewrite this system as follows
%
\begin{align}\label{inflated}
\notag 
&\underbrace{\m{
		C_n	& B_n     & A_n     &         &         &  &  &  \\ 
		& C_{n\!+\!1} & B_{n\!+\!1} & A_{n\!+\!1} &         &  &  &  \\ 
		&         & \ddots  & \ddots  & \ddots  &  &  &  \\ 
		&         &         & \ddots  & \ddots  & \ddots &  &  \\ 
%		&         &         &         & \ddots  & \ddots & \ddots &  \\ 
		&         &         &         & C_{n\!+\!\ell} & B_{n\!+\!\ell} & A_{n\!+\!\ell}
	}}_{=:\cM}
	\! 
	\underbrace{\m{x(n) \\ x(n\!+\!1)  \\ x(n\!+\!2) \\ \vdots \\ x(n\!+\!\ell)}}_{=:\cX} 
	 \\ 
&+ \underbrace{\m{
		D_n &         &         & \\
			& D_{n+1} &  		& \\
			&         & \ddots  & \\
			&         &         & D_{n+\ell}
			}}_{=:\cN}
\underbrace{\m{u(n) \\ u(n\!+\!1)  \\ \vdots \\ u(n\!+\!\ell)}}_{=:\cU} 
	= \! \underbrace{\m{f(n) \\ f(n\!+\!1)  \\ \vdots \\ f(n\!+\!\ell)}}_{=:\cG}, \ \mbox{ for all } n\geq n_0.
\end{align}
%
\begin{definition}\label{shift index}
Suppose that the descriptor system \eqref{eq1.0} satisfies Assumption \ref{Ass3}. At each time point $n$, the minimum number $\ell$ such that by using elementary matrix's row operations, a strangeness-free descriptor system of the form \eqref{sfree-descriptor}
can be extracted from \eqref{inflated} is called the \emph{shift-index} of \eqref{eq1.0}, and be denoted by $\nu(n)$.
\end{definition}
%In order to determine the solution $x(n)$, it would be convenience to use the underlying difference equation \eqref{underlying} than \eqref{sfree-SiDE}. Thus, we introduce the shift-index concept as follows. 
%
%\begin{definition}\label{shift index}
%At each time point $n$, the minimum number $\ell$ such that by using elementary matrix's row operations, an underlying SiDE \eqref{underlying} can be extracted from \eqref{inflated} is called the \emph{shift-index} of \eqref{eq2.2}, and be denoted by $\nu(n)$.
%\end{definition}

We notice that the shift-index $\nu$ is determined pointwise (so it may vary with $n$), while the strangeness-index $\mu$ remains a constant for all $n$ under Assumption \ref{Ass1}. The relation between these indices is given in the following proposition.
%%
%\begin{proposition}\label{pro3.1}
%Consider the SiDE \eqref{eq2.2} and assume that the corresponding IVP is uniquely solvable. If the strangeness-index $\mu$ is well-defined, then so is the shift-index $\nu$. 
%Furthermore, at each $n\geq n_0$, we have that $\mu \leq \nu(n) \leq \mu +2$. 
%\end{proposition}
%%	
%\begin{proof} 	
%Due to the fact that the strangeness-index $\mu$ exists, it means that Algorithm \ref{Alg1} succesfully terminated after $\mu$ index reduction steps (of each orders), and we obtain the strangeness-free form \eqref{sfree-SiDE}. This implies that the strangeness-free SiDE \eqref{sfree-SiDE} is a consequence of the shift-inflated system of level $\mu$. 
%Furthermore, following directly from Definition \ref{shift index} and Corollary \ref{Cor2}, since one need at most two shift to obtain the underlying difference equation \eqref{underlying} from 
%\eqref{sfree-SiDE}, then the shift-index is well-defined and satisfies $\mu \leq \nu(n) \leq \mu +2$. 
%\end{proof}
%
\begin{proposition}\label{pro3.1}
Suppose that the descriptor system \eqref{eq1.0} satisfies Assumption \ref{Ass3}. If the strangeness-index $\mu$ is well-defined, then so is the shift-index $\nu$. Furthermore, at each $n\geq n_0$, we have that $\nu(n) \leq \mu$. 
\end{proposition}
%%	
\begin{proof} 	The first claim is straight forward, since every reformulation step performed in Lemma \ref{lem2.2} is still a consequence of an inflated system \eqref{inflated} with $\ell = \mu$. Furthermore, by definition, $\nu(n) \leq \mu$ for every $n\geq n_0$.
\end{proof}

Next we construct an algorithm in order to select the strangeness-free descriptor system \eqref{sfree-descriptor} from the inflated system \eqref{inflated}. 
For notational convenience, we will follow the Matlab language, \cite{matlab}. Consider the following spaces and matrices
%
\be\label{eq3.3}
\begin{array}{ll}
	\cW &:= \m{ \cM(:,3n+1 : end) & \ \cN(:,n+1 : end) }, \\
	U_1 & \mbox{basis of } \kernel(\cW^T), \ \mbox{and} \ U_{1,\perp} \mbox{basis of } \range(\cW),	
\end{array}
\ee
%
we have that $U_1^T \cW = 0$ and $U_{1,\perp}^T \cW$ has full row rank. Furthermore, the matrix $\m{U^T_1 \\ U^T_{1,\perp}}$ is nonsingular, and hence system \eqref{inflated} is equivalent to the scaled-system below. 
%
\begin{equation}\label{eq3.4a}
U_1^T \cM(:,1 : 3n) \m{x(n) \\ x(n+1) \\ x(n+2)} + U_1^T \cN(:,1:n) u(n) = U_1^T \cG,
\end{equation}
%
\begin{equation}\label{eq3.4b}
U^T_{1,\perp}  \cW \m{x(n\!+\!3) \\ \vdots \\ x(n\!+\!\nu(n)) \\ u(n\!+\!1) \\ \vdots \\ u(n\!+\!\nu(n))} 
\!+\! U^T_{1,\perp} \m{ \cM(:,1\!:\!3n) & \ \cN(:,1\!:\!n)} \! \m{x(n) \\ x(n\!+\!1) \\ x(n\!+\!2) \\ u(n)} \!=\! U_{1,\perp}^T \! \cG.
\end{equation}
%
Notice that due to the full row rank property of $U_{1,\perp}^T \cW$, \eqref{eq3.4b} plays no role in the determination of the strangeness-free descriptor system \eqref{sfree-descriptor}. Thus, \eqref{sfree-descriptor} is a consequence of \eqref{eq3.4a}. 
%
In the following proposition we show that system \eqref{eq3.4a} is not affected by left equivalence transformation.
%
\begin{proposition}
	Consider two left equivalent systems. Then, at the same level $\ell$, their shift-inflated systems of the form \eqref{inflated} are also left equivalent. Consequently, system \eqref{eq3.4a} is not affected by left equivalence transformation.
\end{proposition}
%
\begin{proof} Let us assume that  \eqref{eq1.0} is left equivalent to the SiDE 
%
\begin{equation}\label{eq3.6}
\tA_{n} x(n+2) + \tB_{n} x(n+1) + \tC_{n} x(n)  + \tD_{n} u(n) = \tf(n),  \mbox{ for all } n\geq n_0.
\end{equation}
%
Thus, there exists a pointwise nonsingular matrix sequence $\{P_n\}_{n\geq n_0}$ such that 
%
\[ \m{\tA_{n} & \tB_{n} & \tC_{n} & \tD_{n}} = P_n \m{A_{n} & B_{n} & C_{n} & D_{n} } \mbox{ and } \tf(n) = P_n f(n) \mbox{ for all } n\geq n_0. \]
%
Therefore, the shift-inflated system of level $\ell$ to \eqref{eq3.6} takes the form
%
\begin{equation}\label{eq3.7}
\tcM \cX + \tilde{\cN} \cU = \tilde{\cG}, 
\end{equation}
%
where the matrix coefficients are
%
\[
\tcM \!=\! \diag(P_n,...,P_{n+\ell}) \ \cM, \ \tilde{\cN} \!=\! \diag(P_n,...,P_{n+\ell}) \ \cN, \ \tilde{\cG} \!=\! \diag(P_n,...,P_{n+\ell}) \cG.
\]
%
This follows that two systems \eqref{inflated} and \eqref{eq3.7} are left equivalent, which finishes the proof.
\end{proof}

For notational convenience, let us rewrite system \eqref{eq3.4a} as	
%
\be\label{eq3.13}
\m{\chA & \ \chB & \ \chC & \vline \ \chD} \m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) \\  u(n)} =  \chG. 
\ee
%	

\begin{lemma}\label{lem4.2} Consider the matrices $T_{i,\perp}$, $T_i$, $i=1$,...,$4$, $W_{1,\perp}$, $W_1$, $\chU$ as in Lemma \ref{lem1.5}. Then, system \eqref{eq3.13} has the same solution set as the following system
%
\begin{align}\label{eq3.14}
\m{
	T_{1,\perp}^T \chA 	 & \ T_{1,\perp}^T \chB  		& \ T_{1,\perp}^T \chC  		& \vline & T_{1,\perp}^T \chD \\
	%	0 					 & \ T_{1}^T \chB 	 	 		& \ T_{1}^T \chC 		 		& \vline & T_{1}^T \chD 		\\
	%	0 					 & \ W_{1}^T  T_{1} \chB 	 	& \ W_{1}^T  T_{1}^T  \chC 	 	& \vline & 0 \\
	0 					 & \ T_{2,\perp}^T W_{1}^T T_{1}^T  \chB 	 	& \ T_{2,\perp}^T W_{1}^T T_{1}^T  \chC 	 	& \vline & 0 \\
	0 					 & 0 	 						& \  T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC 	 	& \vline & 0 \\ 
	0 					 & 0 	 						& 0												 	 	& \vline & 0 \\ \hline \\[-0.35cm]
	%	0 					 & \ W_{1,\perp}^T  T_{1}^T  \chB  & \ W_{1,\perp}^T  T_{1}^T  \chC 	& \vline & W_{1,\perp}^T  T_{1}^T  \chD \\
	0 					 & \ T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chB  & \ T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chC 	& \vline & T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chD \\
	0 					 & 0  							& \ T_{3}^T W_{1,\perp}^T  T_{1}^T  \chC 	& \vline & T_{3}^T W_{1,\perp}^T  T_{1}^T  \chD} 
\! \m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n) \\  u(n)} =  \chU \chG.
% U:= \m{ T_{1,\perp}^T					 \\
%T_{2,\perp}^T W_{1}^T T_{1}^T		 \\
%T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T   \\
%T_{4}^T T_{2}^T W_{1}^T  T_{1}^T         \\
%T_{4}^T T_{2}^T W_{1}^T  T_{1}^T         \\
%T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \\
%T_{3}^T W_{1,\perp}^T  T_{1}^T}
\end{align}
%	
Here the matrices $T_{1,\perp}^T \chA$, $T_{2,\perp}^T W_{1}^T T_{1}^T  \chB$,  $T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chB$, $T_{2,\perp}^T W_{1}^T T_{1}^T  \chC$, \linebreak and $\m{ T_{3,\perp}^T W_{1,\perp}^T  T_{1}^T  \chD \\ T_{3}^T W_{1,\perp}^T  T_{1}^T  \chD}$ have full row rank.
\end{lemma}
\begin{proof}
Scaling system \eqref{eq3.13} with the matrix $\chU$ obtained from Lemma \ref{lem1.5} iii), we directly obtain \eqref{eq3.14}.
\end{proof}

In the following theorem we answer the question how to derive the strangeness-free formulation \eqref{sfree-descriptor} from \eqref{eq3.14}. 

\begin{theorem}\label{thm3.1} Assume that the shift index $\nu$ to the descriptor system \eqref{eq1.0} is well-defined pointwise. Furthermore, suppose that \eqref{eq1.0} satisfies Assumption \ref{Ass3}. Then, from the system \eqref{eq3.4a}, we can extract the following system
%Then, there exists a matrix $\cS$ of appropriate sizes, whose rows are pairwise orthogonal, such that by scaling the system \eqref{eq3.4a} with $\cS$, we obtain
%
\begin{equation}\label{sfree form}
\pm{\hr_{2} \\ \hr_{1} \\ \hr_{0} \\ \\[-0.35cm] \hat{\vphi}_{1} \\ \hat{\vphi}_{0} \\ \hv} \ 
\m{\hA_{n,1}& \hB_{n,1}    & \hC_{n,1}     \\
	0		& \hB_{n,2}    & \hC_{n,2}     \\
	0		&    0          & \hC_{n,3}		 \\ \hline \\[-0.35cm]
	0    & \hB_{n,5}    & \hC_{n,5}     \\
	0    & 0          & \hC_{n,6}    } \!
\m{x(n\!+\!2) \\ x(n\!+\!1) \\ x(n)} \!+\! 
\m{\hD_{n,1} \\ 0 \\ 0  \\ \hline \\[-0.35cm] \hD_{n,4} \\ \hD_{n,5}} \! u(n) \!=\! \m{\hG_1 \\ \hG_2 \\ \hG_3 \\ \hline \hG_4 \\ \hG_5}, \mbox{ for all } n\geq n_0,
\end{equation}
%
where the matrices $\m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}}$, $\m{\hD_{n,4} \\ \hD_{n,5}}$ 
have full row rank for all $n\geq n_0$.
Consequently, the descriptor system \eqref{eq1.0} has exactly the same solution set as the strangeness-free descriptor system \eqref{sfree form}.
\end{theorem}
\begin{proof}
The key idea here is, that we will extract system \eqref{sfree form} from \eqref{eq3.14} by removing the hidden redundancy in first two block row equations. Applying Lemma \ref{lem1.4} for two following matrix pairs
%
\[
\left(T_{2,\perp}^T W_{1}^T T_{1}^T \chB, \ T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC \right), \left(T_{1,\perp}^T \chA, \m{T_{2,\perp}^T W_{1}^T T_{1}^T \chB \\ T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC } \right).
\]
%
we obtain two unitary matrices $\m{S^{(i)}_{n} \\ Z^{(i)}_{n}} \in \C^{r_i,r_i}$, $i=1,2$ such that both pairs 
%
\[
\left(S^{(1)}_{n} T_{2,\perp}^T W_{1}^T T_{1}^T \chB, \ T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC \right), 
\left(S^{(2)}_{n}T_{1,\perp}^T \chA, \m{S^{(1)}_{n} T_{2,\perp}^T W_{1}^T T_{1}^T \chB \\ T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC } \right).
\]
% 
have no hidden redundancy. Scale the first and second block row equations of \eqref{eq3.14} with $S^{(2)}_{n}$ and $S^{(1)}_{n}$ respectively, we obtain the first two block row equations of \eqref{sfree form}. The third, fifth and sixth equations of \eqref{eq3.14} are the last three block row equations of \eqref{sfree form}.
\end{proof}
%\newpage
We summarize our result in the following algorithm.
%
\begin{algorithm}[H]
	\caption{Strangeness-free formulation for SiDEs using shift arrays}
	\label{Alg2}
	\begin{algorithmic}[1]
		\State \textbf{Input:} The SiDE  \eqref{eq1.0}.
		\State \textbf{Return:} The strangeness-free descriptor system \eqref{sfree form}.
		\State Set $\ell := 0$.
		\State Construct the shift-inflated system of level $\ell$, and rewrite it in the form \eqref{inflated}.
		\State Find $U_1$ as in \eqref{eq3.3} and construct system \eqref{eq3.4a}.
		\State Find $T_i$, $T_{i,\perp}$, $i=1,...,4$, $W_1$, $W_{1,\perp}$ and construct \eqref{eq3.14} as in Lemma \ref{lem1.5}.
		%
		%\algstore{myalg}
		%\end{algorithmic}
		%\end{algorithm}
		%
		%\begin{algorithm}[H]
		%\begin{algorithmic}[1]
		%\algrestore{myalg}
		% 
		\State Applying Lemma \ref{lem1.2} to reduce the hidden redundancies in two matrix pairs $\left(T_{2,\perp}^T W_{1}^T T_{1}^T \chB, \ T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC \right)$, $\left(T_{1,\perp}^T \chA, \m{T_{2,\perp}^T W_{1}^T T_{1}^T \chB \\ T_{4,\perp}^T T_{2}^T W_{1}^T  T_{1}^T  \chC } \right)$, and hence, to obtain system \eqref{sfree form}.
		%
		\IF{$\rank \m{\hA_{n,1} \\ \hB_{n+1,2} \\ \hC_{n+2,3}} + \rank \m{\hD_{n,4} \\ \hD_{n,5}} = d $} STOP. 
		\ELSE{ set $\ell := \ell + 1$ and go to 4} 
		\ENDIF
	\end{algorithmic}
\end{algorithm}

In order to illustrate Algorithm \ref{Alg2}, we consider a three link robot arm \cite{Hou94a} in the following example.

\begin{example}
Our consider system is of the form
%
\begin{equation*}%\label{robot arm}
\m{M_0 & 0 \\ 0 & 0} \ddot{x}(t) + \m{G_0 & 0 \\ 0 & 0} \dot{x}(t) + \m{K_0 & H_0^T \\ H_0 & 0} x(t) = \m{B_0 \\ 0} u(t).
\end{equation*}
%
Here $M_0$ represents the nonsingular mass matrix, $G_0$ the coefficient matrix associated
with damping, centrifugal, gravity, and Coriolis forces, $K_0$ the stiffness matrix, and $H_0$ the constraint. A simple discretized version of this system takes the form
%
\begin{align*}
& \m{M_0 & 0 \\ 0 & 0} \dfrac{x(n+2)-2x(n+1)+x(n)}{h^2}  + \m{G_0 & 0 \\ 0 & 0} \dfrac{x(n+2)-x(n+1)}{h} \\ & + \m{K_0 & H_0^T \\ H_0 & 0} x(n) = \m{B_0 \\ 0} u(n).
\end{align*}
%
where $h$ is the discretized stepsize.

As a simple example, let us take $M_0 = G_0 = K_0 = H_0= B_0 = 1$, $h=0.01$. Then, Algorithm \ref{Alg2} terminates after two steps and hence, the shift index is $\nu(n)=2$ for all $n\geq n_0$. 
Furthermore, we notice that no matter forward or backward approximations has been chosen for the derivative $\dot{x}(t)$, the index remains unchanged $\nu(n)=2$. Nevertheless, the resulting strangeness-free descriptor systems are different.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{section4_lti}
% \input{section4_ltv}

%============================================================================
\bibliographystyle{abbrv}
\bibliography{Phi_July_2018}

%\appendix
%\section{Proof of Lemma \ref{lem5.1}}\label{appendixA}



\end{document}
